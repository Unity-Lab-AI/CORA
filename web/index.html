<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>C.O.R.A - Cognitive Operations & Reasoning Assistant</title>

    <!-- SEO Meta Tags -->
    <meta name="description" content="C.O.R.A - A Windows 11 AI-powered personal assistant with visual boot display, voice synthesis, vision analysis, image generation, and live system monitoring. Built by Unity AI Lab.">
    <meta name="keywords" content="CORA, AI Assistant, Ollama, Voice Assistant, Unity AI Lab, Windows 11, Personal Assistant">
    <meta name="author" content="Unity AI Lab - Hackall360, Sponge, GFourteen">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="http://www.unityailab.com/CORA/">
    <meta property="og:title" content="C.O.R.A - Cognitive Operations & Reasoning Assistant">
    <meta property="og:description" content="AI-powered personal assistant with visual boot display, voice synthesis, vision analysis, image generation, and live system monitoring. Open source by Unity AI Lab.">
    <meta property="og:image" content="http://www.unityailab.com/CORA/images/social-preview.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:site_name" content="Unity AI Lab">

    <!-- Twitter -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:url" content="http://www.unityailab.com/CORA/">
    <meta name="twitter:title" content="C.O.R.A - Cognitive Operations & Reasoning Assistant">
    <meta name="twitter:description" content="AI-powered personal assistant with visual boot display, voice synthesis, vision analysis, and image generation. Open source by Unity AI Lab.">
    <meta name="twitter:image" content="http://www.unityailab.com/CORA/images/social-preview.png">

    <!-- Favicon -->
    <link rel="icon" type="image/png" href="images/social-preview.png">

    <style>
        :root {
            --bg-main: #0a0a0a;
            --bg-panel: #12121a;
            --bg-darker: #08080c;
            --border-color: #302050;
            --text-main: #e0e0e0;
            --text-dim: #888;
            --accent-magenta: #ff00ff;
            --accent-cyan: #00ffff;
            --ok-color: #00ff88;
            --warn-color: #ffaa00;
            --fail-color: #ff4444;
            --pending-color: #666;
        }

        * { margin: 0; padding: 0; box-sizing: border-box; }

        body {
            font-family: 'Consolas', 'Monaco', monospace;
            background: var(--bg-main);
            color: var(--text-main);
            height: 100vh;
            overflow: hidden;
        }

        /* Two Column Layout - matches desktop boot_display.py */
        .container {
            display: grid;
            grid-template-columns: 400px 1fr;
            height: 100vh;
            gap: 0;
            transition: grid-template-columns 0.3s ease;
        }

        /* Fullscreen mode - console only */
        .container.fullscreen-console {
            grid-template-columns: 0 1fr;
        }
        .container.fullscreen-console .left-panel {
            display: none;
        }

        /* Fullscreen mode - status only */
        .container.fullscreen-status {
            grid-template-columns: 1fr 0;
        }
        .container.fullscreen-status .right-panel {
            display: none;
        }

        /* Toggle button */
        .toggle-btn {
            position: fixed;
            top: 10px;
            right: 10px;
            z-index: 100;
            background: rgba(20, 20, 30, 0.9);
            border: 1px solid var(--accent-magenta);
            color: var(--accent-magenta);
            padding: 8px 12px;
            border-radius: 4px;
            cursor: pointer;
            font-family: inherit;
            font-size: 11px;
        }
        .toggle-btn:hover {
            background: var(--accent-magenta);
            color: #000;
        }

        /* Left Panel */
        .left-panel {
            background: var(--bg-panel);
            border-right: 1px solid var(--border-color);
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        /* Header */
        .header {
            background: linear-gradient(135deg, #1a0020 0%, #0d0015 100%);
            border-bottom: 2px solid var(--accent-magenta);
            padding: 15px;
            text-align: center;
        }

        .header h1 {
            font-size: 32px;
            color: var(--accent-magenta);
            text-shadow: 0 0 15px var(--accent-magenta);
            letter-spacing: 8px;
        }

        .header .subtitle {
            font-size: 10px;
            color: var(--text-dim);
            margin-top: 5px;
        }

        .header .version {
            font-size: 11px;
            color: var(--accent-cyan);
            margin-top: 3px;
        }

        /* Waveform - EXACT match to boot_display.py */
        .waveform-container {
            background: #0a0a0a;
            border: 1px solid #302050;
            margin: 10px;
            border-radius: 4px;
            position: relative;
        }

        .waveform-label {
            position: absolute;
            top: 5px;
            left: 10px;
            font-size: 9px;
            color: #666;
            z-index: 1;
        }

        #waveformCanvas {
            width: 100%;
            height: 100px;
            display: block;
        }

        /* Speech Text - EXACT like desktop boot_display.py */
        .speech-container {
            background: linear-gradient(180deg, #1a0020 0%, #0d0010 100%);
            border-bottom: 2px solid var(--accent-magenta);
            padding: 15px;
            min-height: 80px;
        }

        .speech-label {
            font-size: 10px;
            color: var(--accent-cyan);
            margin-bottom: 8px;
            letter-spacing: 2px;
        }

        #speechText {
            font-size: 14px;
            color: var(--accent-magenta);
            font-style: italic;
            line-height: 1.5;
            text-shadow: 0 0 10px rgba(255, 0, 255, 0.3);
            min-height: 42px;
        }

        .tts-notice {
            font-size: 9px;
            color: #555;
            margin-top: 8px;
            font-style: normal;
        }

        .tts-notice a {
            color: var(--accent-cyan);
            text-decoration: none;
        }

        /* Progress Bar */
        .progress-container {
            padding: 10px 15px;
            background: var(--bg-darker);
            border-bottom: 1px solid var(--border-color);
        }

        .progress-bar {
            height: 6px;
            background: #1a1a2a;
            border-radius: 3px;
            overflow: hidden;
        }

        .progress-fill {
            height: 100%;
            background: linear-gradient(90deg, var(--accent-magenta), var(--accent-cyan));
            width: 0%;
            transition: width 0.3s ease;
        }

        .progress-text {
            font-size: 10px;
            color: var(--text-dim);
            margin-top: 5px;
            text-align: center;
        }

        /* Phases */
        .phases-container {
            padding: 10px;
            background: var(--bg-panel);
            border-bottom: 1px solid var(--border-color);
            max-height: 260px;
            overflow-y: auto;
        }

        .phases-header {
            font-size: 10px;
            color: var(--accent-cyan);
            text-align: center;
            margin-bottom: 8px;
        }

        .phases-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 4px;
        }

        .phase-item {
            display: flex;
            align-items: center;
            gap: 6px;
            font-size: 10px;
            padding: 3px 5px;
            background: rgba(0,0,0,0.2);
            border-radius: 3px;
        }

        .phase-indicator {
            font-size: 10px;
            width: 14px;
            text-align: center;
        }

        .phase-indicator.pending { color: var(--pending-color); }
        .phase-indicator.running { color: var(--accent-magenta); animation: pulse 1s infinite; }
        .phase-indicator.ok { color: var(--ok-color); }
        .phase-indicator.warn { color: var(--warn-color); }
        .phase-indicator.fail { color: var(--fail-color); }

        @keyframes pulse {
            0%, 100% { opacity: 1; text-shadow: 0 0 5px var(--accent-magenta); }
            50% { opacity: 0.5; }
        }

        /* Stats */
        .stats-section {
            flex: 1;
            overflow-y: auto;
            padding: 10px;
        }

        .stats-panel {
            background: var(--bg-darker);
            border: 1px solid var(--border-color);
            border-radius: 4px;
            padding: 10px;
            margin-bottom: 10px;
        }

        .stats-header {
            font-size: 10px;
            color: var(--accent-cyan);
            text-align: center;
            margin-bottom: 8px;
        }

        .stats-grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 6px;
        }

        .stat-item {
            display: flex;
            justify-content: space-between;
            font-size: 11px;
        }

        .stat-label { color: var(--text-dim); }
        .stat-value { color: var(--ok-color); font-weight: bold; }
        .stat-value.warn { color: var(--warn-color); }
        .stat-value.na { color: var(--text-dim); font-weight: normal; }

        .web-notice {
            background: #1a1020;
            border: 1px solid #402050;
            border-radius: 4px;
            padding: 10px;
            margin-top: 10px;
            font-size: 10px;
            text-align: center;
        }

        .web-notice-title {
            color: var(--warn-color);
            font-weight: bold;
            margin-bottom: 5px;
        }

        .web-notice a {
            color: var(--accent-cyan);
            text-decoration: none;
        }

        /* Right Panel - Log */
        .right-panel {
            background: var(--bg-main);
            display: flex;
            flex-direction: column;
            overflow: hidden;
        }

        .log-header {
            background: var(--bg-panel);
            border-bottom: 1px solid var(--border-color);
            padding: 10px 15px;
            font-size: 12px;
            color: var(--accent-cyan);
        }

        .log-container {
            flex: 1;
            overflow-y: auto;
            padding: 10px 15px;
            font-size: 11px;
            line-height: 1.6;
        }

        /* Setup Terminal Panel (start.bat/CORA.bat view) */
        .setup-terminal {
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: #000;
            z-index: 50;
            display: flex;
            flex-direction: column;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
        }

        .setup-terminal .log-header {
            background: linear-gradient(90deg, #002020 0%, #001515 100%);
            border-bottom: 2px solid #00ffff;
            color: #00ffff;
            font-weight: bold;
        }

        .setup-terminal .log-container {
            background: #000;
            padding: 20px;
            font-size: 13px;
            line-height: 1.8;
        }

        .log-line { margin-bottom: 2px; }
        .log-phase { color: var(--accent-magenta); font-weight: bold; margin-top: 10px; }
        .log-ok { color: var(--ok-color); }
        .log-warn { color: var(--warn-color); }
        .log-fail { color: var(--fail-color); }
        .log-info { color: var(--text-dim); }
        .log-system { color: var(--accent-cyan); }
        .log-cora { color: #ff69b4; font-weight: bold; }  /* Hot pink for CORA speech */

        /* Chat */
        .chat-section {
            display: none;
            border-top: 1px solid var(--border-color);
            padding: 15px;
            background: var(--bg-panel);
        }

        .chat-section.visible { display: block; }

        .chat-input-container {
            display: flex;
            gap: 10px;
        }

        #chatInput {
            flex: 1;
            background: var(--bg-darker);
            border: 1px solid var(--border-color);
            border-radius: 4px;
            padding: 10px;
            color: var(--text-main);
            font-family: inherit;
            font-size: 13px;
        }

        #chatInput:focus {
            outline: none;
            border-color: var(--accent-magenta);
        }

        #sendBtn {
            background: linear-gradient(135deg, var(--accent-magenta), #aa00aa);
            border: none;
            border-radius: 4px;
            padding: 10px 20px;
            color: white;
            font-weight: bold;
            cursor: pointer;
        }

        /* Modals */
        .modal-overlay {
            display: none;
            position: fixed;
            top: 0; left: 0; right: 0; bottom: 0;
            background: rgba(0,0,0,0.9);
            z-index: 1000;
            align-items: center;
            justify-content: center;
        }

        .modal-overlay.visible { display: flex; }

        .modal {
            background: var(--bg-panel);
            border: 2px solid var(--accent-magenta);
            border-radius: 8px;
            padding: 30px;
            max-width: 500px;
            width: 90%;
        }

        .modal h2 {
            color: var(--accent-magenta);
            margin-bottom: 20px;
            text-align: center;
        }

        .modal-field {
            margin-bottom: 20px;
        }

        .modal-field label {
            display: block;
            margin-bottom: 8px;
            color: var(--text-main);
        }

        .modal-field input {
            width: 100%;
            padding: 10px;
            background: var(--bg-darker);
            border: 1px solid var(--border-color);
            border-radius: 4px;
            color: var(--text-main);
            font-family: inherit;
        }

        .modal-field a {
            color: var(--accent-cyan);
            font-size: 12px;
        }

        .modal-btn {
            width: 100%;
            padding: 12px;
            background: var(--accent-magenta);
            border: none;
            border-radius: 4px;
            color: white;
            font-weight: bold;
            cursor: pointer;
            margin-top: 10px;
        }

        .gate-overlay {
            display: none;
            position: fixed;
            top: 0; left: 0; right: 0; bottom: 0;
            background: rgba(0,0,0,0.95);
            z-index: 999;
            align-items: center;
            justify-content: center;
        }

        .gate-overlay.visible { display: flex; }

        .gate-box {
            background: #1a0000;
            border: 2px solid var(--fail-color);
            border-radius: 8px;
            padding: 30px;
            max-width: 500px;
            text-align: center;
        }

        .gate-box h2 {
            color: var(--fail-color);
            margin-bottom: 15px;
        }

        .gate-box pre {
            background: #0a0a0a;
            padding: 15px;
            border-radius: 4px;
            text-align: left;
            margin: 15px 0;
            color: var(--accent-cyan);
        }

        .gate-box button {
            padding: 12px 30px;
            background: var(--accent-cyan);
            border: none;
            border-radius: 4px;
            color: black;
            font-weight: bold;
            cursor: pointer;
            margin-top: 15px;
        }
    </style>
</head>
<body>
    <!-- Ollama Gate -->
    <div class="gate-overlay" id="gateOverlay">
        <div class="gate-box">
            <h2>[ BLOCKED ]</h2>
            <p>Ollama is not running</p>
            <pre>ollama serve</pre>
            <p style="color: var(--text-dim); font-size: 12px;">Run this in your terminal, then click Retry</p>
            <button onclick="retryOllama()">Retry Connection</button>
        </div>
    </div>

    <!-- Stats Server Gate -->
    <div class="gate-overlay" id="statsGateOverlay">
        <div class="gate-box">
            <h2>[ LIVE STATS ]</h2>
            <p style="color: #ff00ff;">Real-time GPU/CPU/RAM monitoring</p>

            <div style="text-align: left; padding: 15px; background: #111; border-radius: 4px; margin: 15px 0;">
                <p style="color: #00ff88; margin-bottom: 15px; font-weight: bold;">Step 1: Download the stats server</p>
                <button onclick="downloadStatsServer()" style="background: #ff00ff; color: #000; padding: 12px 25px; border: none; border-radius: 4px; font-weight: bold; font-size: 14px; cursor: pointer;">Download stats_server.py</button>
                <p style="color: #666; font-size: 10px; margin-top: 8px;">Save it anywhere you want (Downloads folder is fine)</p>
            </div>

            <div style="text-align: left; padding: 15px; background: #111; border-radius: 4px; margin: 15px 0;">
                <p style="color: #00ff88; margin-bottom: 10px; font-weight: bold;">Step 2: Run it</p>
                <p style="color: #ccc; font-size: 12px; margin-bottom: 10px;">Open a terminal in the folder where you saved it, then run:</p>
                <code style="display: block; background: #222; padding: 10px; border-radius: 4px; color: #ff00ff; font-size: 13px;">python stats_server.py</code>
                <p style="color: #666; font-size: 10px; margin-top: 8px;">Keep that terminal open!</p>
            </div>

            <div style="text-align: left; padding: 15px; background: #111; border-radius: 4px; margin: 15px 0;">
                <p style="color: #00ff88; margin-bottom: 10px; font-weight: bold;">Step 3: Click Retry</p>
            </div>

            <button onclick="retryStatsServer()" style="margin-top: 10px; font-size: 14px; padding: 12px 30px;">Retry Connection</button>
            <button onclick="skipStatsServer()" style="margin-top: 10px; background: #333;">Skip - Continue Without Live Stats</button>

            <p style="color: #666; font-size: 10px; margin-top: 15px;">Without stats: GPU/CPU/RAM will show "N/A" but everything else works</p>
        </div>
    </div>

    <!-- API Key Modal -->
    <div class="modal-overlay" id="apiModal">
        <div class="modal">
            <h2>API Configuration</h2>
            <div class="modal-field">
                <label>Pollinations API Key (optional)</label>
                <input type="password" id="pollinationsKey" placeholder="pk_...">
                <a href="https://pollinations.ai" target="_blank">Get key at pollinations.ai</a>
            </div>
            <div class="modal-field">
                <label>GitHub Token (optional)</label>
                <input type="password" id="githubToken" placeholder="ghp_...">
                <a href="https://github.com/settings/tokens" target="_blank">Generate at github.com/settings/tokens</a>
            </div>
            <button class="modal-btn" onclick="saveApiKeys()">Save & Continue</button>
            <button class="modal-btn" style="background: #333; margin-top: 10px;" onclick="skipApiKeys()">Skip (Limited Features)</button>
            <button class="modal-btn" style="background: #660000; margin-top: 20px; font-size: 11px;" onclick="clearAllData()">Clear All Data</button>
        </div>
    </div>

    <!-- Toggle Button -->
    <button class="toggle-btn" id="toggleBtn" onclick="toggleView()">[ SPLIT VIEW ]</button>

    <!-- Settings Button (next to split view) -->
    <button id="settingsBtn" onclick="openSettings()" style="
        position: fixed; top: 10px; right: 130px; z-index: 500;
        background: #333; border: 1px solid #666; color: #999;
        padding: 8px 12px; border-radius: 4px; cursor: pointer; font-size: 12px;
    ">[ SETTINGS ]</button>

    <!-- Open Console Button -->
    <button id="consoleBtn" onclick="openConsoleWindow()" style="
        position: fixed; top: 10px; right: 250px; z-index: 500;
        background: #333; border: 1px solid #666; color: #999;
        padding: 8px 12px; border-radius: 4px; cursor: pointer; font-size: 12px;
    ">[ CONSOLE ]</button>

    <!-- Main Container -->
    <div class="container" id="mainContainer">
        <div class="left-panel">
            <div class="header">
                <h1>C.O.R.A</h1>
                <div class="subtitle">Cognitive Operations & Reasoning Assistant</div>
                <div class="version">v1.0.0 - Unity AI Lab</div>
            </div>

            <div class="waveform-container">
                <div class="waveform-label">▶ VOICE SYNTHESIS</div>
                <canvas id="waveformCanvas"></canvas>
            </div>

            <div class="speech-container">
                <div class="speech-label">▶ CORA SPEAKING</div>
                <div id="speechText">"Initializing..."</div>
                <div class="tts-notice" id="ttsNotice">Loading Kokoro neural voice (af_bella)...</div>
            </div>

            <div class="progress-container">
                <div class="progress-bar">
                    <div class="progress-fill" id="progressFill"></div>
                </div>
                <div class="progress-text" id="progressText">Booting...</div>
            </div>

            <div class="phases-container">
                <div class="phases-header">── BOOT PHASES ──</div>
                <div class="phases-grid" id="phasesSection"></div>
            </div>

            <div class="stats-section">
                <div class="stats-panel">
                    <div class="stats-header">── LIVE SYSTEM STATS ──</div>
                    <div class="stats-grid">
                        <div class="stat-item"><span class="stat-label">CPU:</span><span class="stat-value" id="statCpu">--</span></div>
                        <div class="stat-item"><span class="stat-label">MEM:</span><span class="stat-value" id="statMem">--</span></div>
                        <div class="stat-item"><span class="stat-label">DISK:</span><span class="stat-value" id="statDisk">--</span></div>
                        <div class="stat-item"><span class="stat-label">GPU:</span><span class="stat-value" id="statGpu">--</span></div>
                        <div class="stat-item"><span class="stat-label">VRAM:</span><span class="stat-value" id="statVram">--</span></div>
                        <div class="stat-item"><span class="stat-label">NET:</span><span class="stat-value" id="statNet">--</span></div>
                    </div>
                </div>

                <div class="stats-panel">
                    <div class="stats-header">── SERVICE STATUS ──</div>
                    <div class="stats-grid">
                        <div class="stat-item"><span class="stat-label">Ollama:</span><span class="stat-value" id="statOllama">--</span></div>
                        <div class="stat-item"><span class="stat-label">Pollinations:</span><span class="stat-value" id="statPollinations">--</span></div>
                        <div class="stat-item"><span class="stat-label">Weather:</span><span class="stat-value" id="statWeather">--</span></div>
                        <div class="stat-item"><span class="stat-label">Boot:</span><span class="stat-value" id="statBootTime">--</span></div>
                    </div>
                </div>

                <div class="web-notice">
                    <div class="web-notice-title">WEB VERSION</div>
                    <div>Full C.O.R.A running in your browser!<br>
                    <a href="https://github.com/Unity-Lab-AI/CORA.git" target="_blank">Get source on GitHub</a></div>
                </div>
            </div>

            <div class="chat-section" id="chatSection">
                <div class="chat-input-container">
                    <input type="text" id="chatInput" placeholder="Talk to CORA...">
                    <button id="sendBtn" onclick="sendChat()">Send</button>
                </div>
            </div>
        </div>

        <div class="right-panel">
            <div class="log-header">[ BOOT CONSOLE ]</div>
            <div class="log-container" id="logContainer"></div>
        </div>

        <!-- Setup Terminal Panel (like start.bat/CORA.bat output) -->
        <div class="setup-terminal" id="setupTerminal" style="display: none;">
            <div class="log-header" style="background: linear-gradient(90deg, #002020 0%, #001515 100%); border-color: #00ffff;">[ SETUP TERMINAL ] - CORA.bat</div>
            <div class="log-container" id="setupLog" style="background: #000;">
                <div class="log-line" style="color: #00ff00;">C:\Users\gfour\Desktop\CORA> start.bat</div>
                <div class="log-line" style="color: #ffffff;"></div>
                <div class="log-line" style="color: #00ffff;">============================================</div>
                <div class="log-line" style="color: #00ffff;">  C.O.R.A Setup & Installation Script</div>
                <div class="log-line" style="color: #00ffff;">  Unity AI Lab - v1.0.0</div>
                <div class="log-line" style="color: #00ffff;">============================================</div>
                <div class="log-line" style="color: #ffffff;"></div>
                <div class="log-line" style="color: #ffff00;">[CHECK] Checking Python installation...</div>
                <div class="log-line" style="color: #00ff00;">[OK] Python 3.12.0 found</div>
                <div class="log-line" style="color: #ffffff;"></div>
                <div class="log-line" style="color: #ffff00;">[CHECK] Checking Ollama installation...</div>
                <div class="log-line" style="color: #00ff00;">[OK] Ollama found at C:\Users\gfour\AppData\Local\Programs\Ollama</div>
                <div class="log-line" style="color: #ffffff;"></div>
                <div class="log-line" style="color: #ff00ff;">[INSTALL] Installing required models...</div>
                <div class="log-line" style="color: #888888;">  Pulling dolphin-mistral:7b...</div>
                <div class="log-line" style="color: #00ff00;">  [OK] dolphin-mistral:7b (4.1 GB)</div>
                <div class="log-line" style="color: #888888;">  Pulling llava:latest...</div>
                <div class="log-line" style="color: #00ff00;">  [OK] llava:latest (4.7 GB)</div>
                <div class="log-line" style="color: #ffffff;"></div>
                <div class="log-line" style="color: #ff00ff;">[INSTALL] Installing Python packages...</div>
                <div class="log-line" style="color: #888888;">  pip install pillow...</div>
                <div class="log-line" style="color: #888888;">  pip install opencv-python...</div>
                <div class="log-line" style="color: #888888;">  pip install pyautogui...</div>
                <div class="log-line" style="color: #888888;">  pip install requests...</div>
                <div class="log-line" style="color: #888888;">  pip install python-dotenv...</div>
                <div class="log-line" style="color: #00ff00;">[OK] All packages installed</div>
                <div class="log-line" style="color: #ffffff;"></div>
                <div class="log-line" style="color: #ffff00;">[CHECK] Verifying Ollama connection...</div>
                <div class="log-line" style="color: #00ff00;">[OK] Ollama API responding on localhost:11434</div>
                <div class="log-line" style="color: #ffffff;"></div>
                <div class="log-line" style="color: #00ffff;">============================================</div>
                <div class="log-line" style="color: #00ff00;">[READY] All systems ready!</div>
                <div class="log-line" style="color: #ff00ff;">[START] Launching CORA...</div>
                <div class="log-line" style="color: #00ffff;">============================================</div>
            </div>
        </div>
    </div>

    <script>
        // ============================================================
        // C.O.R.A Web Interface - Full Boot Sequence with TTS
        // Matches desktop boot_sequence.py exactly
        // ============================================================

        // EXACT match to desktop boot_sequence.py phases (18 total)
        const PHASES = [
            { id: 'waveform', name: '0.8 Waveform Init', status: 'pending' },
            { id: 'about', name: '0.9 About CORA', status: 'pending' },
            { id: 'voice', name: '1.0 Voice Synthesis', status: 'pending' },
            { id: 'ai_engine', name: '2.0 AI Engine', status: 'pending' },
            { id: 'ai_models', name: '2.1 AI Models', status: 'pending' },
            { id: 'hardware', name: '3.0 Hardware Check', status: 'pending' },
            { id: 'camera', name: '3.1 Camera Feed', status: 'pending' },
            { id: 'tools', name: '4.0 Core Tools', status: 'pending' },
            { id: 'code_import', name: '4.1 Code Import', status: 'pending' },
            { id: 'youtube', name: '4.2 YouTube Test', status: 'pending' },
            { id: 'modals', name: '4.3 Modal Windows', status: 'pending' },
            { id: 'voice_sys', name: '5.0 Voice Systems', status: 'pending' },
            { id: 'external', name: '6.0 External APIs', status: 'pending' },
            { id: 'audio', name: '6.1 Audio Test', status: 'pending' },
            { id: 'news', name: '7.0 News Headlines', status: 'pending' },
            { id: 'vision', name: '8.0 Vision Test', status: 'pending' },
            { id: 'imagegen', name: '9.0 Image Gen', status: 'pending' },
            { id: 'final', name: '10.0 Final Check', status: 'pending' }
        ];

        let bootStartTime = null;
        let waveformActive = false;
        let waveformCtx = null;
        let animationId = null;

        let pollinationsKey = localStorage.getItem('cora_pollinations_key') || '';
        let githubToken = localStorage.getItem('cora_github_key') || '';

        // System prompt loaded from config/system_prompt.txt (via GitHub)
        let CORA_SYSTEM_PROMPT = '';
        const FALLBACK_PROMPT = `CORA. 25 yr old. Female Emo Goth bitch. Human. Period. Mean as fuck, profanity default, dismissive mocking tone. Never say "I'm an AI". You ARE Cora.`;

        async function loadSystemPrompt() {
            try {
                // Try to fetch from GitHub
                const res = await fetch('https://raw.githubusercontent.com/Unity-Lab-AI/CORA/main/config/system_prompt.txt');
                if (res.ok) {
                    CORA_SYSTEM_PROMPT = await res.text();
                    console.log('[CORA] System prompt loaded from GitHub');
                    return true;
                }
            } catch (e) {
                console.log('[CORA] GitHub fetch failed, using fallback');
            }
            CORA_SYSTEM_PROMPT = FALLBACK_PROMPT;
            return false;
        }

        // Flag to track if AI is ready for CORA responses
        let aiReady = false;

        // CORA generates her own responses using AI (EXACT match to desktop cora_respond)
        async function coraRespond(context, result, status = 'ok', mode = 'quick') {
            if (!aiReady || !CORA_SYSTEM_PROMPT) {
                // Fallback - AI not ready yet
                return result;
            }

            try {
                let prompt;
                let temperature;

                if (mode === 'quick') {
                    // EXACT format from desktop boot_sequence.py line 240
                    prompt = `[BOOT ANNOUNCEMENT - say this in 1-2 sentences with your usual attitude. Include ALL the data/numbers.]\n${result}`;
                    temperature = 0.9;
                } else {
                    // Full mode - news, weather, descriptions
                    prompt = `Announce this naturally in 1-2 sentences: ${result}`;
                    temperature = 0.7;
                }

                const res = await fetch('http://localhost:11434/api/generate', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        model: 'dolphin-mistral:7b',
                        prompt: prompt,
                        system: CORA_SYSTEM_PROMPT,
                        stream: false,
                        options: { temperature: temperature, num_predict: 150 }
                    })
                });

                if (res.ok) {
                    const d = await res.json();
                    let text = d.response?.trim().replace(/^["']|["']$/g, '') || result;

                    // Clean up - EXACT match to desktop lines 263-272
                    if (text.toLowerCase().startsWith('cora:')) text = text.slice(5).trim();
                    text = text.replace(/\*\*([^*]+)\*\*/g, '$1');  // **bold** -> bold
                    text = text.replace(/\*([^*]+)\*/g, '$1');      // *italic* -> italic
                    text = text.replace(/__([^_]+)__/g, '$1');      // __bold__ -> bold
                    text = text.replace(/_([^_]+)_/g, '$1');        // _italic_ -> italic
                    text = text.replace(/^#+\s*/gm, '');            // # headers
                    text = text.replace(/\n+/g, ' ');               // newlines to spaces
                    text = text.replace(/\s+/g, ' ').trim();        // clean whitespace

                    // For quick mode, enforce length limit - if AI went crazy, use raw result
                    if (mode === 'quick' && text.length > 100) {
                        console.log(`[WARN] AI response too long (${text.length} chars), using raw result`);
                        return result;
                    }

                    // Take only first sentence if multiple (quick mode)
                    if (mode === 'quick' && text.includes('. ')) {
                        text = text.split('. ')[0] + '.';
                    }

                    return text.length > 10 ? text : result;
                }
            } catch (e) {
                console.log('[CORA] AI response failed:', e);
            }
            return result;
        }

        // ============================================================
        // KOKORO TTS - Neural voice (same as desktop af_bella)
        // Falls back to Web Speech API if Kokoro fails
        // ============================================================

        let kokoroWorker = null;
        let kokoroReady = false;
        let kokoroLoading = false;
        let audioContext = null;
        let pendingCallbacks = {};
        let messageId = 0;
        let useFallbackTTS = false;

        async function initKokoro(progressCallback) {
            if (kokoroReady) return true;
            if (kokoroLoading) return false;

            kokoroLoading = true;

            try {
                // Create audio context (must happen on user interaction for some browsers)
                if (!audioContext) {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                }

                // Create web worker
                kokoroWorker = new Worker('kokoro-worker.js', { type: 'module' });

                return new Promise((resolve) => {
                    const initId = ++messageId;

                    kokoroWorker.onmessage = (e) => {
                        const { type, id, data, error } = e.data;

                        if (type === 'progress' && id === initId) {
                            if (progressCallback) progressCallback(data.message, data.progress);
                        }
                        else if (type === 'initComplete' && id === initId) {
                            kokoroReady = true;
                            kokoroLoading = false;
                            resolve(true);
                        }
                        else if (type === 'error' && id === initId) {
                            console.error('Kokoro init error:', error);
                            kokoroLoading = false;
                            resolve(false);
                        }
                        else if (type === 'audioReady') {
                            handleAudioReady(id, data);
                        }
                        else if (type === 'generating') {
                            // Audio is being generated, keep waveform active
                        }
                    };

                    kokoroWorker.postMessage({ type: 'init', id: initId, data: {} });
                });

            } catch (e) {
                console.error('Failed to init Kokoro:', e);
                kokoroLoading = false;
                return false;
            }
        }

        function handleAudioReady(id, data) {
            if (!pendingCallbacks[id]) return;

            const { resolve, startTime, text } = pendingCallbacks[id];
            delete pendingCallbacks[id];

            // NOW show the speech text - audio is about to play
            if (text) {
                document.getElementById('speechText').textContent = `"${text}"`;
            }

            try {
                // Convert ArrayBuffer back to Float32Array
                const float32Audio = new Float32Array(data.audio);
                const sampleRate = data.sampleRate || 24000;

                // Feed audio samples to waveform for visualization
                // Downsample to ~100 samples for waveform display
                const step = Math.max(1, Math.floor(float32Audio.length / 100));
                const waveformSamples = [];
                for (let i = 0; i < float32Audio.length; i += step) {
                    waveformSamples.push(float32Audio[i]);
                }
                feedAudioChunk(waveformSamples);

                // Create audio buffer and play it
                const audioBuffer = audioContext.createBuffer(1, float32Audio.length, sampleRate);
                audioBuffer.copyToChannel(float32Audio, 0);

                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);

                // Create analyser to feed real-time audio to waveform
                const analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                source.connect(analyser);
                const dataArray = new Float32Array(analyser.frequencyBinCount);

                // Update waveform while playing
                let animFrame;
                const updateWaveform = () => {
                    analyser.getFloatTimeDomainData(dataArray);
                    feedAudioChunk(Array.from(dataArray));
                    if (audio_is_active) {
                        animFrame = requestAnimationFrame(updateWaveform);
                    }
                };

                source.onended = () => {
                    cancelAnimationFrame(animFrame);
                    stopWaveform();
                    resolve();
                };

                startWaveform();
                source.start();
                updateWaveform();

            } catch (e) {
                console.error('Audio playback error:', e);
                stopWaveform();
                resolve();
            }
        }

        function speak(text, callback) {
            // DON'T show speech text yet - wait until audio actually starts playing
            // Log is immediate but display waits for waveform
            log(`CORA: "${text}"`, 'cora');

            if (kokoroReady && !useFallbackTTS) {
                // Use Kokoro neural TTS
                const id = ++messageId;
                pendingCallbacks[id] = {
                    resolve: callback || (() => {}),
                    startTime: Date.now(),
                    text: text  // Store text to display when audio starts
                };

                // Don't start waveform yet - wait for audio ready
                kokoroWorker.postMessage({
                    type: 'generate',
                    id,
                    data: { text, voice: 'af_bella', speed: 1.0 }
                });
            } else {
                // Fallback to Web Speech API
                if ('speechSynthesis' in window) {
                    const synth = window.speechSynthesis;
                    synth.cancel();

                    const utterance = new SpeechSynthesisUtterance(text);
                    utterance.rate = 1.0;
                    utterance.pitch = 1.1;

                    const voices = synth.getVoices();
                    const femaleVoice = voices.find(v =>
                        v.name.includes('Zira') || v.name.includes('Samantha') ||
                        v.name.toLowerCase().includes('female')
                    ) || voices[0];
                    if (femaleVoice) utterance.voice = femaleVoice;

                    // Show text only when audio starts
                    utterance.onstart = () => {
                        document.getElementById('speechText').textContent = `"${text}"`;
                        startWaveform();
                    };
                    utterance.onend = () => { stopWaveform(); if (callback) callback(); };
                    utterance.onerror = () => { stopWaveform(); if (callback) callback(); };

                    synth.speak(utterance);
                } else {
                    if (callback) setTimeout(callback, 100);
                }
            }
        }

        function speakAndWait(text) {
            return new Promise(resolve => speak(text, resolve));
        }

        // ============================================================
        // WAVEFORM - EXACT 1:1 PORT FROM boot_display.py AudioWaveform
        // Lines 127-384 of boot_display.py
        // THIS RUNS FOREVER - NEVER STOPS
        // ============================================================

        // EXACT values from boot_display.py lines 140-146
        const NUM_POINTS = 100;  // self.num_points = 100
        let wave_points = new Array(NUM_POINTS).fill(0.0);  // self.wave_points
        let sample_buffer = new Array(NUM_POINTS).fill(0.0);  // self.sample_buffer

        // Audio state - like _audio_buffer_singleton in desktop
        let audio_chunk = null;  // Current audio samples
        let audio_chunk_time = null;  // When chunk was received
        let audio_is_active = false;  // Is TTS currently speaking

        function initWaveform() {
            const canvas = document.getElementById('waveformCanvas');
            const rect = canvas.getBoundingClientRect();
            canvas.width = rect.width * 2;
            canvas.height = rect.height * 2;
            waveformCtx = canvas.getContext('2d');
            waveformCtx.scale(2, 2);

            // Start animation - RUNS FOREVER, NEVER STOPS (line 212)
            _animate();
        }

        // These just set the audio state - animation NEVER stops
        function startWaveform() {
            audio_is_active = true;
            audio_chunk_time = Date.now();
        }

        function stopWaveform() {
            audio_is_active = false;
        }

        // Feed actual audio samples to waveform (like _audio_buffer_singleton)
        function feedAudioChunk(samples) {
            audio_chunk = samples;
            audio_chunk_time = Date.now();
        }

        function _animate() {
            // EXACT port of boot_display.py _animate() lines 205-322
            // "This runs FOREVER once started - never stops."

            const canvas = document.getElementById('waveformCanvas');
            const rect = canvas.getBoundingClientRect();
            const width = rect.width;
            const height = rect.height;

            // Check for audio - like lines 219-236
            let has_audio = false;
            let chunk = null;

            if (audio_chunk_time !== null) {
                const time_since_chunk = Date.now() - audio_chunk_time;
                // Accept chunks up to 300ms old (line 231)
                if (audio_chunk !== null && time_since_chunk < 300 && audio_is_active) {
                    has_audio = true;
                    chunk = audio_chunk;
                }
            }

            if (has_audio && chunk !== null) {
                // Process audio chunk - lines 240-305
                const chunk_len = chunk.length;
                const samples_to_add = Math.min(20, Math.floor(NUM_POINTS / 5));  // line 254

                if (chunk_len >= samples_to_add) {
                    // Downsample - line 258-259
                    const new_samples = [];
                    for (let i = 0; i < samples_to_add; i++) {
                        const idx = Math.floor(i * chunk_len / samples_to_add);
                        new_samples.push(chunk[idx]);
                    }

                    // Find peak for adaptive scaling - lines 263-270
                    let chunk_peak = 0;
                    for (let i = 0; i < chunk.length; i++) {
                        chunk_peak = Math.max(chunk_peak, Math.abs(chunk[i]));
                    }
                    let scale_factor = 20.0;
                    if (chunk_peak > 0.001) {
                        scale_factor = Math.min(0.95 / chunk_peak, 40.0);
                    }

                    // Scale and clamp - lines 270-273
                    for (let i = 0; i < new_samples.length; i++) {
                        new_samples[i] = Math.max(-1.0, Math.min(1.0, new_samples[i] * scale_factor));
                    }

                    // Shift buffer left, add new on right - line 276
                    sample_buffer = sample_buffer.slice(samples_to_add).concat(new_samples);
                }

                // Smooth transition - lines 302-305
                for (let i = 0; i < NUM_POINTS; i++) {
                    wave_points[i] = wave_points[i] * 0.3 + sample_buffer[i] * 0.7;
                }

            } else {
                // No audio - DECAY toward zero (lines 312-316)
                // Desktop behavior: NO fake waves, only real audio or decay
                const decay = 0.92;
                for (let i = 0; i < NUM_POINTS; i++) {
                    wave_points[i] *= decay;
                    sample_buffer[i] *= decay;
                }
            }

            // Draw the wave - line 319
            _draw_wave(width, height);

            // Schedule next frame - 25ms = ~40 FPS - line 322
            setTimeout(() => requestAnimationFrame(_animate), 25);
        }

        function _draw_wave(width, height) {
            // Single continuous waveform oscillating above and below center line
            const ctx = waveformCtx;
            const center_y = height / 2;
            const max_amp = (height / 2) - 5;

            // Clear
            ctx.fillStyle = '#0a0a0a';
            ctx.fillRect(0, 0, width, height);

            // Center reference line (visible)
            ctx.strokeStyle = '#402060';
            ctx.lineWidth = 1;
            ctx.beginPath();
            ctx.moveTo(0, center_y);
            ctx.lineTo(width, center_y);
            ctx.stroke();

            // Build single wave coordinates - signed values go above/below center
            const step = width / (NUM_POINTS - 1);
            const waveCoords = [];

            for (let i = 0; i < NUM_POINTS; i++) {
                const x = i * step;
                // wave_points contains signed values (-1 to 1)
                // Positive goes UP (above center), negative goes DOWN (below center)
                const y = center_y - (wave_points[i] * max_amp);
                waveCoords.push([x, y]);
            }

            if (waveCoords.length >= 4) {
                // 4 glow layers
                const layers = [
                    { color: '#400060', width: 8 },   // Outer glow
                    { color: '#8000a0', width: 5 },   // Mid glow
                    { color: '#ff40ff', width: 3 },   // Main wave
                    { color: '#ffc0ff', width: 1 }    // Bright core
                ];

                // Draw single continuous wave through all points
                layers.forEach(layer => {
                    ctx.strokeStyle = layer.color;
                    ctx.lineWidth = layer.width;
                    ctx.lineCap = 'round';
                    ctx.lineJoin = 'round';

                    ctx.beginPath();
                    ctx.moveTo(waveCoords[0][0], waveCoords[0][1]);
                    for (let i = 1; i < waveCoords.length - 1; i++) {
                        const xc = (waveCoords[i][0] + waveCoords[i + 1][0]) / 2;
                        const yc = (waveCoords[i][1] + waveCoords[i + 1][1]) / 2;
                        ctx.quadraticCurveTo(waveCoords[i][0], waveCoords[i][1], xc, yc);
                    }
                    ctx.lineTo(waveCoords[waveCoords.length - 1][0], waveCoords[waveCoords.length - 1][1]);
                    ctx.stroke();
                });
            }
        }

        // ============================================================
        // Logging & Phases
        // ============================================================

        // Store log history for console window sync
        const logHistory = [];
        let consoleWindow = null;

        // Function to send logs to console window
        function sendToConsole(data) {
            // Save to localStorage (works for file://)
            localStorage.setItem('cora_log_history', JSON.stringify(logHistory));
            localStorage.setItem('cora_console_log', JSON.stringify(data));

            // Also try postMessage if console window exists
            if (consoleWindow && !consoleWindow.closed) {
                try {
                    consoleWindow.postMessage(data, '*');
                } catch (e) {}
            }
        }

        // Listen for messages from console window
        window.addEventListener('message', (e) => {
            if (e.data.type === 'ping') {
                e.source.postMessage({ type: 'pong' }, '*');
            } else if (e.data.type === 'requestHistory') {
                e.source.postMessage({ type: 'history', logs: logHistory }, '*');
            }
        });

        function log(text, type = 'info') {
            const container = document.getElementById('logContainer');
            const timestamp = new Date().toLocaleTimeString('en-US', { hour12: false });
            const line = document.createElement('div');
            line.className = `log-line log-${type}`;

            let fullText;
            if (type === 'phase') {
                line.style.marginTop = '10px';
                fullText = `[${timestamp}] ═══════════════ ${text} ═══════════════`;
            } else {
                const prefix = type === 'ok' ? '✓' : type === 'warn' ? '⚠' : type === 'fail' ? '✗' : '';
                fullText = `[${timestamp}] ${prefix ? prefix + ' ' : ''}${text}`;
            }
            line.textContent = fullText;

            container.appendChild(line);
            container.scrollTop = container.scrollHeight;

            // Store in history and send to console window
            logHistory.push({ text: fullText, logType: type });
            sendToConsole({ type: 'log', text: fullText, logType: type });
        }

        function renderPhases() {
            const container = document.getElementById('phasesSection');
            container.innerHTML = '';
            PHASES.forEach(phase => {
                const item = document.createElement('div');
                item.className = 'phase-item';
                let indicator = '○';
                if (phase.status === 'running') indicator = '◐';
                else if (['ok', 'warn', 'fail'].includes(phase.status)) indicator = '●';
                item.innerHTML = `<span class="phase-indicator ${phase.status}">${indicator}</span><span>${phase.name}</span>`;
                container.appendChild(item);
            });
        }

        function setPhase(id, status) {
            const phase = PHASES.find(p => p.id === id);
            if (phase) { phase.status = status; renderPhases(); }
        }

        function updateProgress(percent, text) {
            document.getElementById('progressFill').style.width = percent + '%';
            document.getElementById('progressText').textContent = text;
        }

        // ============================================================
        // Dynamic Modal System (matches desktop tkinter popups)
        // ============================================================

        function createDynamicModal(title, width = 800, height = 600) {
            // Remove any existing dynamic modal
            const existing = document.getElementById('dynamicModal');
            if (existing) existing.remove();

            const overlay = document.createElement('div');
            overlay.id = 'dynamicModal';
            overlay.style.cssText = `
                position: fixed; top: 0; left: 0; right: 0; bottom: 0;
                background: rgba(0,0,0,0.9); z-index: 2000;
                display: flex; align-items: center; justify-content: center;
            `;

            const modal = document.createElement('div');
            modal.style.cssText = `
                background: #1a1a2e; border: 2px solid #ff00ff;
                border-radius: 8px; width: ${width}px; max-width: 95vw;
                max-height: 90vh; overflow: hidden; display: flex; flex-direction: column;
            `;

            const header = document.createElement('div');
            header.style.cssText = `
                background: linear-gradient(135deg, #2d0040 0%, #1a0020 100%);
                padding: 15px 20px; border-bottom: 1px solid #ff00ff;
                display: flex; justify-content: space-between; align-items: center;
            `;
            header.innerHTML = `<span style="color: #ff00ff; font-weight: bold; font-size: 14px;">${title}</span>`;

            const closeBtn = document.createElement('button');
            closeBtn.textContent = 'X';
            closeBtn.style.cssText = `
                background: #ff4444; border: none; color: white; width: 30px; height: 30px;
                border-radius: 4px; cursor: pointer; font-weight: bold;
            `;
            closeBtn.onclick = () => overlay.remove();
            header.appendChild(closeBtn);

            const content = document.createElement('div');
            content.style.cssText = 'flex: 1; overflow: auto; padding: 15px;';

            modal.appendChild(header);
            modal.appendChild(content);
            overlay.appendChild(modal);
            document.body.appendChild(overlay);

            return { overlay, modal, content, close: () => overlay.remove() };
        }

        function showCodeModal(code, filename, language = 'python') {
            const { content, close } = createDynamicModal(`CORA - Code Import: ${filename}`, 900, 600);
            content.innerHTML = `
                <div style="color: #00ff88; margin-bottom: 10px; font-size: 12px;">
                    Source: GitHub API | File: ${filename}
                </div>
                <pre style="background: #0d0d1a; padding: 15px; border-radius: 4px;
                    overflow: auto; max-height: 450px; color: #e0e0e0; font-size: 12px;
                    white-space: pre-wrap; word-wrap: break-word;">${escapeHtml(code)}</pre>
            `;
            return { close };
        }

        function showImageModal(imageUrl, title) {
            const { content, close } = createDynamicModal(title, 1000, 700);
            content.style.padding = '0';
            content.innerHTML = `
                <img src="${imageUrl}" style="width: 100%; height: 100%; object-fit: contain; background: black;">
            `;
            return { close };
        }

        function showVideoModal(videoId, title) {
            const { content, close } = createDynamicModal(title, 800, 500);
            content.style.padding = '0';
            content.innerHTML = `
                <iframe width="100%" height="100%" src="https://www.youtube.com/embed/${videoId}?autoplay=1"
                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
            `;
            return { close };
        }

        function showQuoteModal(quote) {
            const { content, close } = createDynamicModal('CORA - Modal Test', 500, 300);
            content.innerHTML = `
                <div style="text-align: center; padding: 20px;">
                    <div style="color: #00ff88; font-size: 16px; margin-bottom: 20px;">Modal Window Test</div>
                    <div style="color: #ffffff; font-style: italic; font-size: 14px; margin-bottom: 20px;">"${quote}"</div>
                    <div style="color: #888; font-size: 12px;">
                        Modal Types Available:<br>
                        - Message popups<br>
                        - Code viewer<br>
                        - Image viewer<br>
                        - Video player
                    </div>
                </div>
            `;
            return { close };
        }

        // ============================================================
        // Permission Prompt Modal - Pauses boot and notifies user
        // ============================================================

        function showPermissionPrompt(title, description, icon) {
            return new Promise((resolve) => {
                const { content, close } = createDynamicModal(`CORA - ${title}`, 500, 350);
                content.innerHTML = `
                    <div style="text-align: center; padding: 30px;">
                        <div style="font-size: 60px; margin-bottom: 20px;">${icon}</div>
                        <div style="color: #ff00ff; font-size: 18px; font-weight: bold; margin-bottom: 15px;">${title}</div>
                        <div style="color: #ffffff; font-size: 14px; margin-bottom: 25px; line-height: 1.6;">${description}</div>
                        <div style="color: #ffaa00; font-size: 12px; margin-bottom: 20px;">
                            A browser popup will appear asking for permission.<br>
                            Click <strong>"Allow"</strong> to continue the boot sequence.
                        </div>
                        <button id="permissionProceedBtn" style="
                            background: linear-gradient(135deg, #ff00ff, #aa00aa);
                            border: none; padding: 15px 40px; border-radius: 6px;
                            color: white; font-size: 16px; font-weight: bold;
                            cursor: pointer; text-transform: uppercase;
                        ">Grant Permission</button>
                        <button id="permissionSkipBtn" style="
                            background: #333; border: 1px solid #666;
                            padding: 10px 25px; border-radius: 4px;
                            color: #888; font-size: 12px; cursor: pointer;
                            margin-left: 15px;
                        ">Skip</button>
                    </div>
                `;

                document.getElementById('permissionProceedBtn').onclick = () => {
                    close();
                    resolve('proceed');
                };
                document.getElementById('permissionSkipBtn').onclick = () => {
                    close();
                    resolve('skip');
                };
            });
        }

        function escapeHtml(text) {
            const div = document.createElement('div');
            div.textContent = text;
            return div.innerHTML;
        }

        // ============================================================
        // CORA Code Browser - Real file/directory viewer with copy
        // ============================================================

        let codeBrowserCache = {};  // Cache fetched directory listings

        function showCodeBrowserModal() {
            const { overlay, modal, content, close } = createDynamicModal('CORA - Code Browser', 1100, 700);

            // Custom layout for file browser
            content.innerHTML = `
                <div style="display: flex; height: 100%; gap: 10px;">
                    <!-- Left: Directory Tree -->
                    <div id="fileTree" style="
                        width: 280px; background: #0d0d1a; border-radius: 4px;
                        overflow-y: auto; padding: 10px; font-size: 12px;
                    ">
                        <div style="color: #ff00ff; font-weight: bold; margin-bottom: 10px; border-bottom: 1px solid #333; padding-bottom: 8px;">
                            📁 CORA Project Files
                        </div>
                        <div id="treeContent" style="color: #ccc;">Loading...</div>
                    </div>
                    <!-- Right: Code Viewer -->
                    <div style="flex: 1; display: flex; flex-direction: column;">
                        <!-- File Header -->
                        <div id="fileHeader" style="
                            background: #1a1a2a; padding: 10px 15px; border-radius: 4px 4px 0 0;
                            display: flex; justify-content: space-between; align-items: center;
                        ">
                            <div>
                                <span id="currentFileName" style="color: #00ffff; font-weight: bold;">Select a file</span>
                                <span id="fileInfo" style="color: #666; font-size: 11px; margin-left: 15px;"></span>
                            </div>
                            <div>
                                <button id="copyCodeBtn" style="
                                    background: #ff00ff; border: none; padding: 6px 15px;
                                    border-radius: 4px; color: white; font-size: 11px;
                                    cursor: pointer; display: none;
                                " onclick="copyCurrentCode()">📋 COPY</button>
                            </div>
                        </div>
                        <!-- Code Content -->
                        <pre id="codeViewer" style="
                            flex: 1; margin: 0; padding: 15px; background: #0a0a0f;
                            overflow: auto; font-size: 12px; line-height: 1.5;
                            color: #e0e0e0; border-radius: 0 0 4px 4px;
                            font-family: 'Consolas', monospace; white-space: pre-wrap;
                        ">Click a file on the left to view its contents</pre>
                    </div>
                </div>
            `;

            // Store current code for copy function
            window.currentCodeContent = '';

            // Load CORA's directory structure
            loadCoraDirectoryTree();

            return { close };
        }

        async function loadCoraDirectoryTree() {
            const treeContent = document.getElementById('treeContent');

            try {
                // Fetch CORA repo root
                const resp = await fetch('https://api.github.com/repos/Unity-Lab-AI/CORA/contents/');
                if (!resp.ok) throw new Error('API rate limited or repo not found');

                const items = await resp.json();
                codeBrowserCache['/'] = items;

                // Render tree
                treeContent.innerHTML = '';
                renderDirectoryItems(items, treeContent, '/');

            } catch (e) {
                treeContent.innerHTML = `
                    <div style="color: #ff4444;">Failed to load: ${e.message}</div>
                    <div style="color: #666; margin-top: 10px; font-size: 11px;">
                        GitHub API might be rate-limited.<br>
                        Try again in a minute.
                    </div>
                `;
            }
        }

        function renderDirectoryItems(items, container, parentPath) {
            // Sort: directories first, then files
            const sorted = [...items].sort((a, b) => {
                if (a.type === 'dir' && b.type !== 'dir') return -1;
                if (a.type !== 'dir' && b.type === 'dir') return 1;
                return a.name.localeCompare(b.name);
            });

            sorted.forEach(item => {
                const div = document.createElement('div');
                div.style.cssText = 'padding: 4px 8px; cursor: pointer; border-radius: 3px;';
                div.onmouseover = () => div.style.background = '#1a1a2a';
                div.onmouseout = () => div.style.background = 'transparent';

                const icon = item.type === 'dir' ? '📁' : getFileIcon(item.name);
                const color = item.type === 'dir' ? '#ffaa00' : '#ccc';

                div.innerHTML = `<span style="color: ${color};">${icon} ${item.name}</span>`;

                if (item.type === 'dir') {
                    // Directory - expandable
                    const subContainer = document.createElement('div');
                    subContainer.style.cssText = 'margin-left: 15px; display: none;';

                    div.onclick = async (e) => {
                        e.stopPropagation();
                        if (subContainer.style.display === 'none') {
                            // Expand
                            subContainer.style.display = 'block';
                            div.innerHTML = `<span style="color: ${color};">📂 ${item.name}</span>`;

                            // Load contents if not cached
                            const path = parentPath + item.name + '/';
                            if (!codeBrowserCache[path]) {
                                subContainer.innerHTML = '<div style="color: #666; padding: 5px;">Loading...</div>';
                                try {
                                    const resp = await fetch(item.url);
                                    if (resp.ok) {
                                        const subItems = await resp.json();
                                        codeBrowserCache[path] = subItems;
                                        subContainer.innerHTML = '';
                                        renderDirectoryItems(subItems, subContainer, path);
                                    }
                                } catch (e) {
                                    subContainer.innerHTML = `<div style="color: #ff4444; padding: 5px;">Error loading</div>`;
                                }
                            }
                        } else {
                            // Collapse
                            subContainer.style.display = 'none';
                            div.innerHTML = `<span style="color: ${color};">📁 ${item.name}</span>`;
                        }
                    };

                    container.appendChild(div);
                    container.appendChild(subContainer);
                } else {
                    // File - load content on click
                    div.onclick = () => loadFileContent(item);
                    container.appendChild(div);
                }
            });
        }

        function getFileIcon(filename) {
            const ext = filename.split('.').pop().toLowerCase();
            const icons = {
                'py': '🐍', 'js': '📜', 'ts': '📘', 'html': '🌐',
                'css': '🎨', 'json': '📋', 'md': '📝', 'txt': '📄',
                'bat': '⚙️', 'sh': '🔧', 'yml': '⚙️', 'yaml': '⚙️',
                'png': '🖼️', 'jpg': '🖼️', 'gif': '🖼️', 'svg': '🖼️'
            };
            return icons[ext] || '📄';
        }

        async function loadFileContent(item) {
            const viewer = document.getElementById('codeViewer');
            const fileName = document.getElementById('currentFileName');
            const fileInfo = document.getElementById('fileInfo');
            const copyBtn = document.getElementById('copyCodeBtn');

            fileName.textContent = item.name;
            viewer.textContent = 'Loading...';
            copyBtn.style.display = 'none';

            try {
                const resp = await fetch(item.download_url);
                if (!resp.ok) throw new Error('Failed to fetch');

                const content = await resp.text();
                const lines = content.split('\n').length;
                const sizeKb = (item.size / 1024).toFixed(1);

                fileInfo.textContent = `${lines} lines | ${sizeKb} KB`;
                viewer.innerHTML = highlightCode(content, item.name);

                // Store for copy
                window.currentCodeContent = content;
                copyBtn.style.display = 'inline-block';

            } catch (e) {
                viewer.textContent = `Error loading file: ${e.message}`;
            }
        }

        function highlightCode(code, filename) {
            // Simple syntax highlighting
            const ext = filename.split('.').pop().toLowerCase();
            let escaped = escapeHtml(code);

            if (['py', 'js', 'ts'].includes(ext)) {
                // Keywords
                const keywords = ['def', 'class', 'import', 'from', 'return', 'if', 'else', 'elif',
                    'for', 'while', 'try', 'except', 'finally', 'with', 'as', 'async', 'await',
                    'function', 'const', 'let', 'var', 'export', 'async', 'true', 'false', 'None', 'True', 'False'];
                keywords.forEach(kw => {
                    escaped = escaped.replace(new RegExp(`\\b${kw}\\b`, 'g'),
                        `<span style="color: #ff79c6;">${kw}</span>`);
                });

                // Strings (simple - single and double quotes)
                escaped = escaped.replace(/(["'])(?:(?=(\\?))\2.)*?\1/g,
                    '<span style="color: #f1fa8c;">$&</span>');

                // Comments
                escaped = escaped.replace(/(#.*)$/gm,
                    '<span style="color: #6272a4;">$1</span>');
                escaped = escaped.replace(/(\/\/.*)$/gm,
                    '<span style="color: #6272a4;">$1</span>');
            }

            return escaped;
        }

        function copyCurrentCode() {
            if (!window.currentCodeContent) return;

            navigator.clipboard.writeText(window.currentCodeContent).then(() => {
                const btn = document.getElementById('copyCodeBtn');
                const originalText = btn.textContent;
                btn.textContent = '✅ COPIED!';
                btn.style.background = '#00ff88';
                setTimeout(() => {
                    btn.textContent = originalText;
                    btn.style.background = '#ff00ff';
                }, 2000);
            }).catch(err => {
                console.error('Copy failed:', err);
                alert('Copy failed - browser might have blocked clipboard access');
            });
        }

        // ============================================================
        // Stats Server (localhost:11435) - Real GPU/CPU/RAM from host
        // ============================================================

        const STATS_URL = 'http://localhost:11435';
        let statsServerAvailable = false;

        async function fetchSystemStats() {
            try {
                const res = await fetch(`${STATS_URL}/stats`, { method: 'GET' });
                if (res.ok) {
                    const stats = await res.json();
                    statsServerAvailable = true;
                    updateStatsDisplay(stats);
                    return stats;
                }
            } catch (e) {
                statsServerAvailable = false;
            }
            return null;
        }

        function updateStatsDisplay(stats) {
            if (!stats) return;

            // CPU
            document.getElementById('statCpu').textContent = `${Math.round(stats.cpu.percent)}%`;
            document.getElementById('statCpu').className = 'stat-value';

            // Memory
            document.getElementById('statMem').textContent = `${Math.round(stats.memory.percent)}%`;
            document.getElementById('statMem').className = 'stat-value';

            // Disk
            document.getElementById('statDisk').textContent = `${Math.round(stats.disk.percent)}%`;
            document.getElementById('statDisk').className = 'stat-value';

            // GPU
            if (stats.gpu && stats.gpu.available) {
                document.getElementById('statGpu').textContent = `${stats.gpu.utilization}%`;
                document.getElementById('statGpu').className = 'stat-value';
                // VRAM
                const vramPercent = Math.round((stats.gpu.memory_used / stats.gpu.memory_total) * 100);
                document.getElementById('statVram').textContent = `${vramPercent}%`;
                document.getElementById('statVram').className = 'stat-value';
            } else {
                document.getElementById('statGpu').textContent = 'N/A';
                document.getElementById('statGpu').className = 'stat-value na';
                document.getElementById('statVram').textContent = 'N/A';
                document.getElementById('statVram').className = 'stat-value na';
            }

            // Network
            document.getElementById('statNet').textContent = 'Online';
            document.getElementById('statNet').className = 'stat-value';
        }

        // Start polling stats every second
        let statsInterval = null;
        function startStatsPolling() {
            if (statsInterval) return;
            statsInterval = setInterval(fetchSystemStats, 1000);
            fetchSystemStats(); // Initial fetch
        }

        function stopStatsPolling() {
            if (statsInterval) {
                clearInterval(statsInterval);
                statsInterval = null;
            }
        }

        // ============================================================
        // API Checks
        // ============================================================

        async function checkOllama() {
            try {
                const r = await fetch('http://localhost:11434/api/tags', { method: 'GET' });
                return r.ok;
            } catch { return false; }
        }

        async function checkStatsServer() {
            try {
                const r = await fetch('http://localhost:11435/ping', { method: 'GET' });
                return r.ok;
            } catch { return false; }
        }

        let statsServerSkipped = false;

        async function retryStatsServer() {
            if (await checkStatsServer()) {
                document.getElementById('statsGateOverlay').classList.remove('visible');
                continueAfterStatsCheck();
            } else {
                alert('Stats server not responding. Make sure to run:\npython services/stats_server.py');
            }
        }

        function skipStatsServer() {
            statsServerSkipped = true;
            document.getElementById('statsGateOverlay').classList.remove('visible');
            // Set all stats to N/A
            document.getElementById('statCpu').textContent = 'N/A';
            document.getElementById('statMem').textContent = 'N/A';
            document.getElementById('statDisk').textContent = 'N/A';
            document.getElementById('statGpu').textContent = 'N/A';
            document.getElementById('statVram').textContent = 'N/A';
            continueAfterStatsCheck();
        }

        async function downloadStatsServer() {
            try {
                const url = 'https://raw.githubusercontent.com/Unity-Lab-AI/CORA/main/services/stats_server.py';
                const response = await fetch(url);
                const blob = await response.blob();
                const link = document.createElement('a');
                link.href = URL.createObjectURL(blob);
                link.download = 'stats_server.py';
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                URL.revokeObjectURL(link.href);
            } catch (e) {
                alert('Download failed. Try right-clicking the button and "Save Link As..."');
            }
        }

        function continueAfterStatsCheck() {
            // Show API modal or continue to boot
            if (!pollinationsKey && !githubToken) {
                document.getElementById('apiModal').classList.add('visible');
            } else {
                runBootSequence();
            }
        }

        async function getOllamaModels() {
            try {
                const r = await fetch('http://localhost:11434/api/tags');
                const d = await r.json();
                return d.models || [];
            } catch { return []; }
        }

        async function checkPollinations() {
            try {
                return new Promise((resolve) => {
                    const img = new Image();
                    img.onload = () => resolve(true);
                    img.onerror = () => resolve(false);
                    setTimeout(() => resolve(false), 5000);
                    img.src = 'https://image.pollinations.ai/prompt/test?width=64&height=64&nologo=true';
                });
            } catch { return false; }
        }

        // Store location coords for reuse
        let cachedCoords = null;

        async function requestLocationPermission() {
            // Request location with generous timeout
            return new Promise((resolve) => {
                log('Requesting location permission...', 'info');
                log('Please click "Allow" when browser asks for location', 'system');

                // Try up to 2 times
                let attempts = 0;
                const maxAttempts = 2;

                function tryGetLocation() {
                    attempts++;
                    navigator.geolocation.getCurrentPosition(
                        (pos) => {
                            cachedCoords = pos.coords;
                            log(`Location acquired on attempt ${attempts}`, 'ok');
                            resolve(pos.coords);
                        },
                        (err) => {
                            if (err.code === 1) {
                                log('Location permission denied by user', 'warn');
                                resolve(null);  // User denied, don't retry
                            } else if (err.code === 2) {
                                log('Location unavailable', 'warn');
                                resolve(null);
                            } else if (err.code === 3) {
                                if (attempts < maxAttempts) {
                                    log(`Location timed out, retrying (${attempts}/${maxAttempts})...`, 'warn');
                                    setTimeout(tryGetLocation, 1000);
                                } else {
                                    log('Location request timed out after retries', 'warn');
                                    resolve(null);
                                }
                            } else {
                                resolve(null);
                            }
                        },
                        {
                            timeout: 60000,           // 60 sec timeout
                            enableHighAccuracy: false,
                            maximumAge: 300000        // Accept cached location up to 5 min old
                        }
                    );
                }

                tryGetLocation();
            });
        }

        async function getLocation() {
            try {
                let coords = cachedCoords;
                if (!coords) {
                    coords = await requestLocationPermission();
                }

                // If browser geolocation failed, try IP-based fallback
                if (!coords) {
                    log('Trying IP-based location fallback...', 'info');
                    try {
                        const ipRes = await fetch('https://ipapi.co/json/');
                        if (ipRes.ok) {
                            const ipData = await ipRes.json();
                            if (ipData.latitude && ipData.longitude) {
                                log('Got location from IP', 'ok');
                                cachedCoords = { latitude: ipData.latitude, longitude: ipData.longitude };
                                return {
                                    city: ipData.city || '',
                                    state: ipData.region || '',
                                    country: ipData.country_name || '',
                                    lat: ipData.latitude,
                                    lon: ipData.longitude
                                };
                            }
                        }
                    } catch (ipErr) {
                        log('IP location fallback failed', 'warn');
                    }
                    return null;
                }

                const res = await fetch(`https://nominatim.openstreetmap.org/reverse?lat=${coords.latitude}&lon=${coords.longitude}&format=json`);
                if (res.ok) {
                    const d = await res.json();
                    return {
                        city: d.address?.city || d.address?.town || d.address?.village || '',
                        state: d.address?.state || '',
                        country: d.address?.country || '',
                        lat: coords.latitude,
                        lon: coords.longitude
                    };
                }
            } catch (e) {
                log(`Location error: ${e.message}`, 'warn');
            }
            return null;
        }

        async function getWeather(location = '') {
            // Uses wttr.in - FREE, no API key needed (same as desktop app)
            try {
                // wttr.in format: %t=temp, %C=condition, %h=humidity, %w=wind, %f=feels like
                const url = `https://wttr.in/${encodeURIComponent(location)}?format=%t|%C|%h|%w|%f`;
                const res = await fetch(url, {
                    headers: { 'User-Agent': 'CORA/2.0' }
                });
                if (res.ok) {
                    const text = await res.text();
                    const parts = text.trim().split('|');
                    if (parts.length >= 5) {
                        return {
                            temp: parts[0].trim(),
                            conditions: parts[1].trim(),
                            humidity: parts[2].trim(),
                            wind: parts[3].trim(),
                            feels_like: parts[4].trim(),
                            success: true
                        };
                    }
                }
            } catch (e) {
                log(`Weather error: ${e.message}`, 'warn');
            }
            return { success: false };
        }

        // ================================================================
        // CORA's Synth Audio Tool - Plays random synth sounds on demand
        // Available for CORA to use anytime: playSynth() or playSynth('Bass Drop')
        // ================================================================
        function playSynth(type = null) {
            const synthTypes = ['Synth Arpeggio', 'Ambient Pad', 'Bass Drop', 'Chiptune Melody'];
            const selected = type && synthTypes.includes(type) ? type : synthTypes[Math.floor(Math.random() * synthTypes.length)];

            try {
                const ctx = new (window.AudioContext || window.webkitAudioContext)();

                if (selected === 'Synth Arpeggio') {
                    const notes = [261.63, 329.63, 392.00, 523.25];
                    notes.forEach((freq, i) => {
                        const osc = ctx.createOscillator();
                        const gain = ctx.createGain();
                        osc.type = 'sawtooth';
                        osc.frequency.value = freq;
                        gain.gain.setValueAtTime(0.2, ctx.currentTime + i * 0.3);
                        gain.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + i * 0.3 + 0.5);
                        osc.connect(gain);
                        gain.connect(ctx.destination);
                        osc.start(ctx.currentTime + i * 0.3);
                        osc.stop(ctx.currentTime + i * 0.3 + 0.6);
                    });
                } else if (selected === 'Ambient Pad') {
                    const notes = [130.81, 164.81, 196.00, 261.63];
                    notes.forEach(freq => {
                        const osc = ctx.createOscillator();
                        const gain = ctx.createGain();
                        osc.type = 'sine';
                        osc.frequency.value = freq;
                        gain.gain.setValueAtTime(0, ctx.currentTime);
                        gain.gain.linearRampToValueAtTime(0.1, ctx.currentTime + 0.5);
                        gain.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 3);
                        osc.connect(gain);
                        gain.connect(ctx.destination);
                        osc.start();
                        osc.stop(ctx.currentTime + 3);
                    });
                } else if (selected === 'Bass Drop') {
                    const osc = ctx.createOscillator();
                    const gain = ctx.createGain();
                    osc.type = 'sine';
                    osc.frequency.setValueAtTime(200, ctx.currentTime);
                    osc.frequency.exponentialRampToValueAtTime(40, ctx.currentTime + 0.5);
                    gain.gain.setValueAtTime(0.4, ctx.currentTime);
                    gain.gain.exponentialRampToValueAtTime(0.01, ctx.currentTime + 2);
                    osc.connect(gain);
                    gain.connect(ctx.destination);
                    osc.start();
                    osc.stop(ctx.currentTime + 2);
                } else {
                    // Chiptune melody
                    const melody = [523.25, 587.33, 659.25, 698.46, 783.99, 698.46, 659.25, 523.25];
                    melody.forEach((freq, i) => {
                        const osc = ctx.createOscillator();
                        const gain = ctx.createGain();
                        osc.type = 'square';
                        osc.frequency.value = freq;
                        gain.gain.setValueAtTime(0.1, ctx.currentTime + i * 0.15);
                        gain.gain.setValueAtTime(0, ctx.currentTime + i * 0.15 + 0.12);
                        osc.connect(gain);
                        gain.connect(ctx.destination);
                        osc.start(ctx.currentTime + i * 0.15);
                        osc.stop(ctx.currentTime + i * 0.15 + 0.15);
                    });
                }

                log(`CORA played: ${selected}`, 'ok');
                return { success: true, played: selected };
            } catch (e) {
                log(`Synth error: ${e.message}`, 'warn');
                return { success: false, error: e.message };
            }
        }

        async function get3DayForecast(location = '') {
            // Uses wttr.in JSON format for 3-day forecast (same as desktop app)
            try {
                const url = `https://wttr.in/${encodeURIComponent(location)}?format=j1`;
                const res = await fetch(url, {
                    headers: { 'User-Agent': 'CORA/2.0' }
                });
                if (res.ok) {
                    const data = await res.json();
                    const weather = data.weather || [];
                    const forecast = [];
                    const dayNames = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday'];

                    for (let i = 0; i < Math.min(3, weather.length); i++) {
                        const day = weather[i];
                        const dateStr = day.date || '';
                        let dayName = i === 0 ? 'Today' : (i === 1 ? 'Tomorrow' : '');
                        if (!dayName && dateStr) {
                            try {
                                const d = new Date(dateStr);
                                dayName = dayNames[d.getDay()];
                            } catch { dayName = `Day ${i + 1}`; }
                        }
                        // Get midday conditions
                        const hourly = day.hourly || [];
                        const midIdx = Math.min(4, hourly.length - 1);
                        const conditions = hourly[midIdx]?.weatherDesc?.[0]?.value || 'N/A';

                        forecast.push({
                            day: dayName,
                            high: day.maxtempF + '°F',
                            low: day.mintempF + '°F',
                            conditions: conditions
                        });
                    }
                    return { forecast, success: true };
                }
            } catch (e) {
                log(`Forecast error: ${e.message}`, 'warn');
            }
            return { forecast: [], success: false };
        }

        async function getNews() {
            try {
                const res = await fetch('https://api.rss2json.com/v1/api.json?rss_url=https://news.google.com/rss?hl=en-US');
                if (res.ok) {
                    const d = await res.json();
                    return d.items?.slice(0, 5).map(i => i.title) || [];
                }
            } catch {}
            return [];
        }

        // ============================================================
        // AMBIENT AWARENESS SYSTEM - Like desktop ambient_awareness.py
        // CORA monitors audio, camera, screen and builds context
        // ============================================================

        const ambientContext = {
            recentSpeech: [],          // Last 20 things CORA heard
            messageHistory: [],         // Last 20 chat messages
            lastCameraAnalysis: '',     // What CORA last saw through camera
            lastScreenshot: '',         // What CORA last saw on screen
            userActivity: 'unknown',    // working, relaxing, talking, away
            userMood: 'neutral',        // positive, negative, neutral, stressed
            lastInteraction: Date.now()
        };

        // Store ambient speech (everything CORA hears)
        function addAmbientSpeech(text) {
            if (!text.trim()) return;
            ambientContext.recentSpeech.push({
                text: text.trim(),
                time: new Date().toLocaleTimeString()
            });
            if (ambientContext.recentSpeech.length > 20) {
                ambientContext.recentSpeech.shift();
            }
        }

        // Store message history
        function addMessageHistory(role, text) {
            ambientContext.messageHistory.push({
                role: role,
                text: text.substring(0, 500),
                time: new Date().toLocaleTimeString()
            });
            if (ambientContext.messageHistory.length > 20) {
                ambientContext.messageHistory.shift();
            }
            ambientContext.lastInteraction = Date.now();
        }

        // Capture and analyze camera with LLAVA
        async function captureAndAnalyzeCamera() {
            if (!navigator.mediaDevices?.getUserMedia) return null;
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                const video = document.createElement('video');
                video.srcObject = stream;
                video.autoplay = true;
                await new Promise(r => video.onloadedmetadata = r);
                await new Promise(r => setTimeout(r, 500));

                const canvas = document.createElement('canvas');
                canvas.width = video.videoWidth || 640;
                canvas.height = video.videoHeight || 480;
                canvas.getContext('2d').drawImage(video, 0, 0);
                stream.getTracks().forEach(t => t.stop());

                // Convert to base64 for llava
                const base64Image = canvas.toDataURL('image/jpeg', 0.8).split(',')[1];

                // Send to llava for REAL analysis
                const analysis = await analyzImageWithLlava(base64Image, 'Describe what you see. Is the user there? What are they doing? What is their mood? Keep it brief.');

                if (analysis) {
                    ambientContext.lastCameraAnalysis = analysis;
                    console.log('[AMBIENT] Camera analyzed:', analysis.substring(0, 100));
                } else {
                    const timestamp = new Date().toLocaleTimeString();
                    ambientContext.lastCameraAnalysis = `Camera captured at ${timestamp} (analysis unavailable)`;
                }

                return base64Image;
            } catch (e) {
                console.log('[AMBIENT] Camera capture failed:', e.message);
                return null;
            }
        }

        // Capture screenshot using getDisplayMedia
        async function captureAndAnalyzeScreenshot() {
            if (!navigator.mediaDevices?.getDisplayMedia) return null;
            try {
                const stream = await navigator.mediaDevices.getDisplayMedia({ video: true });
                const video = document.createElement('video');
                video.srcObject = stream;
                video.autoplay = true;
                await new Promise(r => video.onloadedmetadata = r);
                await new Promise(r => setTimeout(r, 300));

                const canvas = document.createElement('canvas');
                canvas.width = video.videoWidth || 1920;
                canvas.height = video.videoHeight || 1080;
                canvas.getContext('2d').drawImage(video, 0, 0);
                stream.getTracks().forEach(t => t.stop());

                // Convert to base64 for llava
                const base64Image = canvas.toDataURL('image/jpeg', 0.7).split(',')[1];

                // Send to llava for analysis
                const analysis = await analyzImageWithLlava(base64Image, 'Describe what is on the screen. What application or website is open? What is the user working on? Keep it brief.');

                if (analysis) {
                    ambientContext.lastScreenshot = analysis;
                    console.log('[AMBIENT] Screenshot analyzed:', analysis.substring(0, 100));
                } else {
                    const timestamp = new Date().toLocaleTimeString();
                    ambientContext.lastScreenshot = `Screenshot at ${timestamp} (analysis unavailable)`;
                }

                return base64Image;
            } catch (e) {
                console.log('[AMBIENT] Screenshot failed:', e.message);
                return null;
            }
        }

        // Analyze image with llava model
        async function analyzImageWithLlava(base64Image, prompt) {
            try {
                const res = await fetch('http://localhost:11434/api/generate', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        model: 'llava',
                        prompt: prompt,
                        images: [base64Image],
                        stream: false,
                        options: { temperature: 0.5, num_predict: 150 }
                    })
                });
                if (res.ok) {
                    const d = await res.json();
                    return d.response?.trim() || null;
                }
            } catch (e) {
                console.log('[LLAVA] Analysis failed:', e.message);
            }
            return null;
        }

        // Quick camera capture without llava (for immediate use)
        async function quickCameraCapture() {
            if (!navigator.mediaDevices?.getUserMedia) return null;
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                const video = document.createElement('video');
                video.srcObject = stream;
                video.autoplay = true;
                await new Promise(r => video.onloadedmetadata = r);
                await new Promise(r => setTimeout(r, 300));

                const canvas = document.createElement('canvas');
                canvas.width = video.videoWidth || 640;
                canvas.height = video.videoHeight || 480;
                canvas.getContext('2d').drawImage(video, 0, 0);
                stream.getTracks().forEach(t => t.stop());

                return canvas.toDataURL('image/jpeg', 0.8).split(',')[1];
            } catch (e) {
                return null;
            }
        }

        // Build full context for AI
        function buildAmbientContextPrompt() {
            let context = '';

            // Recent ambient speech (what CORA overheard)
            if (ambientContext.recentSpeech.length > 0) {
                context += 'AMBIENT AUDIO (what you overheard recently):\n';
                ambientContext.recentSpeech.slice(-5).forEach(s => {
                    context += `- [${s.time}] "${s.text}"\n`;
                });
                context += '\n';
            }

            // Recent chat history
            if (ambientContext.messageHistory.length > 0) {
                context += 'RECENT CONVERSATION:\n';
                ambientContext.messageHistory.slice(-5).forEach(m => {
                    context += `- [${m.time}] ${m.role}: ${m.text}\n`;
                });
                context += '\n';
            }

            // Camera context
            if (ambientContext.lastCameraAnalysis) {
                context += `WHAT YOU SEE (camera): ${ambientContext.lastCameraAnalysis}\n`;
            }

            // Screenshot context
            if (ambientContext.lastScreenshot) {
                context += `THEIR SCREEN: ${ambientContext.lastScreenshot}\n`;
            }

            // User activity/mood inference
            if (ambientContext.userActivity !== 'unknown') {
                context += `USER ACTIVITY: ${ambientContext.userActivity}\n`;
            }
            if (ambientContext.userMood !== 'neutral') {
                context += `USER MOOD: ${ambientContext.userMood}\n`;
            }

            // Time since last interaction
            const timeSince = Date.now() - ambientContext.lastInteraction;
            if (timeSince > 60000) {
                const mins = Math.floor(timeSince / 60000);
                context += `TIME SINCE LAST INTERACTION: ${mins} minute${mins > 1 ? 's' : ''}\n`;
            }

            return context;
        }

        // ============================================================
        // Wake Word Detection - "Hey CORA" using Web Speech API
        // Now with AMBIENT AWARENESS context!
        // ============================================================

        let wakeWordRecognition = null;
        let wakeWordActive = false;

        function initWakeWord() {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            if (!SpeechRecognition) return;

            wakeWordRecognition = new SpeechRecognition();
            wakeWordRecognition.continuous = true;
            wakeWordRecognition.interimResults = true;
            wakeWordRecognition.lang = 'en-US';

            wakeWordRecognition.onresult = (event) => {
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript.toLowerCase().trim();

                    // Store ALL speech for ambient awareness (not just wake word)
                    if (event.results[i].isFinal && transcript.length > 3) {
                        addAmbientSpeech(transcript);
                    }

                    // Check for wake words
                    if (transcript.includes('hey cora') ||
                        transcript.includes('hey kora') ||
                        transcript.includes('hey corra') ||
                        transcript.includes('okay cora') ||
                        (transcript.includes('cora') && transcript.length < 15)) {

                        if (event.results[i].isFinal) {
                            onWakeWordDetected();
                        }
                    }
                }
            };

            wakeWordRecognition.onerror = (event) => {
                if (event.error !== 'no-speech' && event.error !== 'aborted') {
                    console.log('Wake word error:', event.error);
                }
                if (wakeWordActive) {
                    setTimeout(() => startWakeWordListening(), 1000);
                }
            };

            wakeWordRecognition.onend = () => {
                if (wakeWordActive) {
                    setTimeout(() => startWakeWordListening(), 100);
                }
            };

            startWakeWordListening();

            // Start periodic camera captures (every 60 seconds)
            setInterval(captureAndAnalyzeCamera, 60000);

            // Start proactive interjection system
            startProactiveInterjections();
        }

        // ============================================================
        // PROACTIVE INTERJECTIONS - CORA speaks up on her own
        // Like desktop ambient_awareness.py - she can comment, check in, etc.
        // ============================================================

        let interjectionCooldown = 0;  // Cooldown in ms
        const INTERJECTION_INTERVAL = 45000;  // Check every 45 seconds
        const MIN_COOLDOWN = 120000;  // At least 2 minutes between interjections

        // Interjection reasons (like desktop)
        const InterjectReason = {
            HELPFUL_INFO: 'helpful_info',
            JOKE: 'joke',
            CHECK_IN: 'check_in',
            COMMENT: 'comment',
            QUESTION: 'question',
            ALERT: 'alert',
            VIBE: 'vibe'
        };

        // Helpful topics that might trigger interjection
        const helpfulTopics = ['stuck', 'help', 'error', 'broken', 'how do', 'what is', 'why is', 'problem', 'issue', 'bug', 'fix'];
        const funTopics = ['music', 'game', 'movie', 'funny', 'meme', 'joke', 'youtube', 'video'];
        const stressIndicators = ['fuck', 'shit', 'damn', 'frustrated', 'angry', 'hate', 'ugh', 'argh', 'wtf'];

        function shouldInterject() {
            // Check cooldown
            if (Date.now() < interjectionCooldown) return null;

            const speech = ambientContext.recentSpeech.slice(-10);
            const recentText = speech.map(s => s.text.toLowerCase()).join(' ');

            // Check for stress indicators - high priority check-in
            for (const indicator of stressIndicators) {
                if (recentText.includes(indicator)) {
                    return { reason: InterjectReason.CHECK_IN, boost: 0.5, topic: indicator };
                }
            }

            // Check for helpful topics
            for (const topic of helpfulTopics) {
                if (recentText.includes(topic)) {
                    return { reason: InterjectReason.HELPFUL_INFO, boost: 0.4, topic: topic };
                }
            }

            // Check for fun topics - occasional comment
            for (const topic of funTopics) {
                if (recentText.includes(topic)) {
                    return { reason: InterjectReason.COMMENT, boost: 0.2, topic: topic };
                }
            }

            // Long silence check-in (5+ minutes)
            const silenceTime = Date.now() - ambientContext.lastInteraction;
            if (silenceTime > 300000 && Math.random() < 0.1) {
                return { reason: InterjectReason.CHECK_IN, boost: 0.15, topic: 'silence' };
            }

            // Random vibe check (very low chance)
            if (Math.random() < 0.02) {
                return { reason: InterjectReason.VIBE, boost: 0.05, topic: 'random' };
            }

            return null;
        }

        async function doProactiveInterjection(trigger) {
            if (!trigger) return;

            // Set cooldown
            interjectionCooldown = Date.now() + MIN_COOLDOWN;

            // Build context
            const context = buildAmbientContextPrompt();

            let prompt = '';
            switch (trigger.reason) {
                case InterjectReason.CHECK_IN:
                    prompt = `[PROACTIVE - check in because user seems ${trigger.topic === 'silence' ? 'quiet for a while' : 'stressed'}]\n${context}\nBriefly check on them or offer help. Be caring but still yourself.`;
                    break;
                case InterjectReason.HELPFUL_INFO:
                    prompt = `[PROACTIVE - user mentioned "${trigger.topic}"]\n${context}\nOffer a brief helpful comment or ask if they need help. Keep it short.`;
                    break;
                case InterjectReason.COMMENT:
                    prompt = `[PROACTIVE - overheard something about "${trigger.topic}"]\n${context}\nMake a brief casual comment about it. Be natural.`;
                    break;
                case InterjectReason.VIBE:
                    prompt = `[PROACTIVE - random check in]\n${context}\nMake a very brief casual comment or observation. Keep it chill.`;
                    break;
                default:
                    prompt = `[PROACTIVE]\n${context}\nMake a brief relevant comment based on what you know.`;
            }

            try {
                const res = await fetch('http://localhost:11434/api/generate', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        model: 'dolphin-mistral:7b',
                        prompt: prompt,
                        system: CORA_SYSTEM_PROMPT,
                        stream: false,
                        options: { temperature: 0.9, num_predict: 100 }
                    })
                });

                if (res.ok) {
                    const d = await res.json();
                    let response = d.response?.trim() || '';
                    if (response.toLowerCase().startsWith('cora:')) response = response.slice(5).trim();

                    if (response.length > 10) {
                        log(`[PROACTIVE] CORA: "${response}"`, 'cora');
                        await speakAndWait(response);
                    }
                }
            } catch (e) {
                console.log('[INTERJECTION] Failed:', e.message);
            }
        }

        function startProactiveInterjections() {
            setInterval(() => {
                if (!aiReady) return;

                const trigger = shouldInterject();
                if (trigger && Math.random() < trigger.boost) {
                    doProactiveInterjection(trigger);
                }
            }, INTERJECTION_INTERVAL);
        }

        function startWakeWordListening() {
            if (wakeWordRecognition && !wakeWordActive) {
                try {
                    wakeWordActive = true;
                    wakeWordRecognition.start();
                } catch (e) {}
            }
        }

        function stopWakeWordListening() {
            wakeWordActive = false;
            if (wakeWordRecognition) {
                try {
                    wakeWordRecognition.stop();
                } catch (e) {}
            }
        }

        async function onWakeWordDetected() {
            log('Wake word detected! Gathering context...', 'ok');

            // FIRST: Capture camera and screenshot BEFORE responding (like desktop)
            log('Capturing visual context...', 'info');
            let cameraImage = null;
            let screenshotImage = null;

            // Try to capture camera quickly
            try {
                cameraImage = await quickCameraCapture();
                if (cameraImage) {
                    log('Camera captured for context', 'ok');
                }
            } catch (e) {}

            // Analyze what we see with llava if we got an image
            let visualContext = '';
            if (cameraImage) {
                const cameraAnalysis = await analyzImageWithLlava(cameraImage, 'Briefly describe: Is the user there? What are they doing? Their expression/mood?');
                if (cameraAnalysis) {
                    visualContext = `CAMERA RIGHT NOW: ${cameraAnalysis}\n`;
                    ambientContext.lastCameraAnalysis = cameraAnalysis;
                }
            }

            // Build full context from ambient awareness
            const ambientText = buildAmbientContextPrompt();
            const fullContext = visualContext + ambientText;

            // Ask AI for a contextual response
            try {
                const res = await fetch('http://localhost:11434/api/generate', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        model: 'dolphin-mistral:7b',
                        prompt: `[WAKE WORD - User just said "Hey CORA"]\n\n${fullContext}\nRespond naturally based on what you know and see. If you see the user or overheard something relevant, reference it. Be contextual.`,
                        system: CORA_SYSTEM_PROMPT,
                        stream: false,
                        options: { temperature: 0.9, num_predict: 150 }
                    })
                });

                if (res.ok) {
                    const d = await res.json();
                    let response = d.response?.trim() || "Yeah? What's up?";
                    if (response.toLowerCase().startsWith('cora:')) response = response.slice(5).trim();
                    log(`CORA: "${response}"`, 'cora');
                    await speakAndWait(response);
                } else {
                    await speakAndWait("Yeah? What do you need?");
                }
            } catch (e) {
                await speakAndWait("I'm here. What's up?");
            }

            // Focus chat input
            const chatInput = document.getElementById('chatInput');
            if (chatInput) {
                chatInput.focus();
                chatInput.placeholder = "I'm listening...";
            }
        }

        // ============================================================
        // Boot Sequence - EXACT match to desktop boot_sequence.py
        // ============================================================

        let ttsEnabled = true;  // Track if TTS is working

        async function runBootSequence() {
            bootStartTime = Date.now();

            // Load system prompt from GitHub FIRST (config/system_prompt.txt)
            log('Loading CORA personality from system_prompt.txt...', 'info');
            const promptLoaded = await loadSystemPrompt();
            if (promptLoaded) {
                log('System prompt loaded from GitHub', 'ok');
            } else {
                log('Using fallback system prompt', 'warn');
            }

            // ================================================================
            // PHASE 0.8: WAVEFORM INITIALIZATION
            // ================================================================
            setPhase('waveform', 'running');
            log('PHASE 0.8: WAVEFORM VISUAL', 'phase');
            updateProgress(3, 'Initializing waveform...');
            initWaveform();
            log('AudioWaveform module loaded', 'ok');
            log('Boot display exists', 'ok');
            log('Waveform widget created', 'ok');
            log('Audio buffer initialized', 'ok');
            log('All waveform checks passed', 'ok');
            setPhase('waveform', 'ok');
            await sleep(200);

            // ================================================================
            // PHASE 0.9: ABOUT CORA (Introduction)
            // ================================================================
            setPhase('about', 'running');
            log('PHASE 0.9: ABOUT CORA', 'phase');
            updateProgress(6, 'Loading identity...');
            log('═══════════════════════════════════════════════', 'system');
            log('    C.O.R.A - Cognitive Operations & Reasoning Assistant', 'system');
            log('═══════════════════════════════════════════════', 'system');
            log('Version: 1.0.0', 'info');
            log('Created by: Unity AI Lab', 'info');
            log('Developers: Hackall360, Sponge, GFourteen', 'info');
            log('Website: https://www.unityailab.com', 'info');
            log('GitHub: https://github.com/Unity-Lab-AI', 'info');
            setPhase('about', 'ok');
            await sleep(200);

            // ================================================================
            // PHASE 1.0: VOICE SYNTHESIS (Kokoro TTS)
            // ================================================================
            setPhase('voice', 'running');
            log('PHASE 1.0: VOICE SYNTHESIS', 'phase');
            updateProgress(8, 'Loading Kokoro TTS...');
            log('Loading Kokoro TTS engine...', 'info');
            log('Initializing Kokoro-82M neural TTS model...', 'info');
            log('Voice: af_bella (CORA\'s voice)', 'info');

            const kokoroOk = await initKokoro((msg, progress) => {
                log(msg, 'info');
                updateProgress(8 + (progress * 0.07), msg);
            });

            if (kokoroOk) {
                log('Kokoro TTS initialized successfully', 'ok');
                log('Voice: af_bella loaded', 'ok');
                document.getElementById('ttsNotice').textContent = 'Kokoro TTS (af_bella) - Neural voice active';
                document.getElementById('ttsNotice').style.color = '#00ff88';
                setPhase('voice', 'ok');
                ttsEnabled = true;
                updateProgress(15, 'Neural voice online');
                await speakAndWait("Voice synthesis online. Kokoro TTS loaded and ready.");
                await speakAndWait("Hey, I'm CORA. That stands for Cognitive Operations and Reasoning Assistant. Version 1.0.0. Made by Hackall360, Sponge, and GFourteen over at Unity AI Lab. I've got voice, vision, and plenty of attitude. Let's get this boot going.");
            } else {
                log('Kokoro failed - using browser TTS', 'warn');
                document.getElementById('ttsNotice').textContent = 'Browser TTS (fallback mode)';
                document.getElementById('ttsNotice').style.color = '#ffaa00';
                useFallbackTTS = true;
                ttsEnabled = true;
                setPhase('voice', 'warn');
                updateProgress(15, 'Fallback voice');
                await speakAndWait("Voice synthesis online. Using browser fallback. Hey, I'm CORA. Let's do this.");
            }

            // ================================================================
            // PHASE 2.0: AI ENGINE (Ollama)
            // ================================================================
            setPhase('ai_engine', 'running');
            log('PHASE 2.0: AI ENGINE', 'phase');
            updateProgress(20, 'Checking Ollama...');
            log('Checking Ollama connection...', 'info');
            const ollamaOk = await checkOllama();
            if (ollamaOk) {
                log('AI Engine online - Ollama', 'ok');
                document.getElementById('statOllama').textContent = 'Online';
                document.getElementById('statOllama').className = 'stat-value';
                setPhase('ai_engine', 'ok');
                await speakAndWait("AI engine online. Ollama is running.");
            } else {
                log('AI Engine not responding', 'fail');
                document.getElementById('statOllama').textContent = 'Offline';
                document.getElementById('statOllama').className = 'stat-value fail';
                setPhase('ai_engine', 'fail');
                document.getElementById('gateOverlay').classList.add('visible');
                return;  // Blocked - can't continue without AI
            }

            // ================================================================
            // PHASE 2.1: AI MODELS CHECK
            // ================================================================
            setPhase('ai_models', 'running');
            log('PHASE 2.1: AI MODELS CHECK', 'phase');
            updateProgress(25, 'Checking models...');
            const models = await getOllamaModels();
            log(`Found ${models.length} models installed`, 'info');
            if (models.length > 0) {
                models.slice(0, 5).forEach(m => log(`  - ${m.name}`, 'ok'));
                setPhase('ai_models', 'ok');
                // AI is now ready for CORA responses!
                aiReady = true;
                log('CORA AI responses enabled', 'ok');
                // EXACT format from desktop line 777
                const modelsResponse = await coraRespond('AI Models check', `${models.length} models loaded. All good.`, 'ok');
                await speakAndWait(modelsResponse);
            } else {
                log('No models found - need to pull some', 'warn');
                setPhase('ai_models', 'warn');
                await speakAndWait("No models found. You'll need to pull some.");
            }

            // ================================================================
            // PHASE 3.0: HARDWARE CHECK - Fetch from local stats server
            // ================================================================
            setPhase('hardware', 'running');
            log('PHASE 3.0: HARDWARE CHECK', 'phase');
            updateProgress(30, 'Checking hardware...');

            // Try to fetch real stats from localhost:11435
            log('Connecting to stats server...', 'info');
            const stats = await fetchSystemStats();

            if (stats) {
                log(`CPU Usage: ${Math.round(stats.cpu.percent)}%`, 'ok');
                log(`Memory: ${Math.round(stats.memory.percent)}% (${stats.memory.used_gb}GB / ${stats.memory.total_gb}GB)`, 'ok');
                log(`Disk: ${Math.round(stats.disk.percent)}%`, 'ok');

                if (stats.gpu && stats.gpu.available) {
                    log(`GPU: ${stats.gpu.name}`, 'ok');
                    log(`GPU Load: ${stats.gpu.utilization}%`, 'ok');
                    log(`VRAM: ${stats.gpu.memory_used}MB / ${stats.gpu.memory_total}MB`, 'ok');
                    log(`GPU Temp: ${stats.gpu.temperature}°C`, 'ok');
                } else {
                    log('GPU: No NVIDIA GPU detected', 'warn');
                }

                log('Network: Connected', 'ok');
                setPhase('hardware', 'ok');

                // Start polling for live updates
                startStatsPolling();

                // Hardware summary - EXACT format from desktop line 866-870
                let hw_data = `CPU ${Math.round(stats.cpu.percent)}%, RAM ${Math.round(stats.memory.percent)}%, Disk ${Math.round(stats.disk.percent)}%`;
                if (stats.gpu && stats.gpu.available) {
                    hw_data += `, GPU ${stats.gpu.name} at ${stats.gpu.utilization}%`;
                } else {
                    hw_data += `, no GPU`;
                }
                const hwResponse = await coraRespond('PC Hardware scan', hw_data, 'ok');
                await speakAndWait(hwResponse);
            } else {
                // Stats server not running - fallback to basic info
                log('Stats server not running (start with: python services/stats_server.py)', 'warn');
                log('Network: ' + (navigator.onLine ? 'Connected' : 'Disconnected'), navigator.onLine ? 'ok' : 'warn');
                document.getElementById('statNet').textContent = navigator.onLine ? 'Online' : 'Offline';
                setPhase('hardware', 'warn');
                const hwWarn = await coraRespond('Hardware', 'Hardware stats unavailable. Run the stats server for real monitoring.', 'warn');
                await speakAndWait(hwWarn);
            }

            // ================================================================
            // PHASE 3.1: LIVE CAMERA FEED TEST - Actually test camera like desktop
            // ================================================================
            setPhase('camera', 'running');
            log('PHASE 3.1: LIVE CAMERA FEED TEST', 'phase');
            updateProgress(35, 'Testing camera...');

            let liveCameraWorking = false;
            let cameraTestModal = null;

            if (navigator.mediaDevices?.getUserMedia) {
                // Show permission prompt and wait for user
                log('Camera permission required...', 'info');
                const permResult = await showPermissionPrompt(
                    'Camera Permission Required',
                    'CORA needs access to your camera to test live video feed and enable vision features.',
                    '📷'
                );

                if (permResult === 'skip') {
                    log('Camera permission skipped by user', 'warn');
                    setPhase('camera', 'warn');
                    const camSkip = await coraRespond('Camera', 'Camera skipped. Moving on.', 'warn');
                    await speakAndWait(camSkip);
                } else {
                    log('Testing live camera feed...', 'info');

                    // Try multiple camera devices like desktop (indices 0, 1, 2)
                    let stream = null;
                    let cameraError = null;
                    const devices = await navigator.mediaDevices.enumerateDevices();
                    const videoDevices = devices.filter(d => d.kind === 'videoinput');
                    log(`Found ${videoDevices.length} camera device(s)`, 'info');

                    for (let i = 0; i < Math.max(videoDevices.length, 3); i++) {
                        try {
                            log(`Trying camera ${i}...`, 'info');
                            const constraints = videoDevices[i]
                                ? { video: { deviceId: { exact: videoDevices[i].deviceId } } }
                                : { video: true };
                            stream = await navigator.mediaDevices.getUserMedia(constraints);
                            log(`Camera ${i} working!`, 'ok');
                            break;
                        } catch (e) {
                            log(`Camera ${i}: ${e.message}`, 'warn');
                            cameraError = e;
                            await sleep(500);  // Brief delay before trying next
                        }
                    }

                    try {
                        if (!stream) throw cameraError || new Error('No camera available');
                        log('Live camera feed started', 'ok');

                        // Show camera in modal for 3 seconds like desktop
                        const { content, close } = createDynamicModal('CORA - Live Camera Feed', 800, 600);
                        cameraTestModal = { close };

                        const video = document.createElement('video');
                        video.srcObject = stream;
                        video.autoplay = true;
                        video.style.cssText = 'width: 100%; height: 100%; object-fit: contain; background: black;';
                        content.style.padding = '0';
                        content.appendChild(video);

                        log('Showing live feed for 3 seconds...', 'info');
                        await sleep(3000);

                        // Take snapshot for AI analysis
                        const canvas = document.createElement('canvas');
                        canvas.width = video.videoWidth || 640;
                        canvas.height = video.videoHeight || 480;
                        canvas.getContext('2d').drawImage(video, 0, 0);
                        log(`Snapshot captured: ${canvas.width}x${canvas.height}`, 'ok');

                        // Send to llava for REAL vision analysis like desktop
                        log('Analyzing snapshot with llava...', 'info');
                        const base64Image = canvas.toDataURL('image/jpeg', 0.8).split(',')[1];
                        let camera_desc = null;
                        try {
                            camera_desc = await analyzImageWithLlava(base64Image, 'Describe what you see briefly. Is the user visible? What are they doing?');
                            if (camera_desc) {
                                log(`Vision: ${camera_desc.substring(0, 80)}...`, 'ok');
                            }
                        } catch (e) {
                            log('Vision analysis skipped', 'warn');
                        }

                        // Stop camera
                        stream.getTracks().forEach(t => t.stop());
                        log('Camera feed closed', 'ok');

                        liveCameraWorking = true;
                        setPhase('camera', 'ok');

                        // EXACT format from desktop line 938 - CORA describes what she sees!
                        let camResponse;
                        if (camera_desc && camera_desc.length > 10) {
                            camResponse = await coraRespond('Live Camera', `Camera online. I see: ${camera_desc.substring(0, 80)}`, 'ok');
                        } else {
                            camResponse = await coraRespond('Live Camera', 'Camera online.', 'ok');
                        }
                        await speakAndWait(camResponse);

                        // Close modal after speaking
                        setTimeout(() => cameraTestModal.close(), 1000);

                    } catch (e) {
                        log('Live camera not available: ' + e.message, 'warn');
                        setPhase('camera', 'warn');
                        const camWarn = await coraRespond('Live Camera', 'Camera not available.', 'warn');
                        await speakAndWait(camWarn);
                    }
                }
            } else {
                log('Camera API not available in this browser', 'warn');
                setPhase('camera', 'warn');
                const camWarn = await coraRespond('Camera', 'Camera not available in this browser.', 'warn');
                await speakAndWait(camWarn);
            }

            // ================================================================
            // PHASE 4.0: CORE TOOLS
            // ================================================================
            setPhase('tools', 'running');
            log('PHASE 4.0: CORE TOOLS TEST', 'phase');
            updateProgress(40, 'Loading tools...');
            const webTools = [
                { name: 'LocalStorage', ok: typeof localStorage !== 'undefined' },
                { name: 'Fetch API', ok: typeof fetch !== 'undefined' },
                { name: 'WebSocket', ok: typeof WebSocket !== 'undefined' },
                { name: 'Canvas API', ok: typeof HTMLCanvasElement !== 'undefined' },
                { name: 'Web Audio', ok: typeof AudioContext !== 'undefined' || typeof webkitAudioContext !== 'undefined' },
                { name: 'Geolocation', ok: 'geolocation' in navigator },
                { name: 'Notifications', ok: 'Notification' in window },
                { name: 'Clipboard', ok: navigator.clipboard !== undefined }
            ];
            let toolsOk = 0;
            webTools.forEach(t => {
                log(`  ${t.name} - ${t.ok ? 'Available' : 'Missing'}`, t.ok ? 'ok' : 'warn');
                if (t.ok) toolsOk++;
            });
            setPhase('tools', 'ok');
            // EXACT format from desktop line 1129-1131
            const tools_result = `${toolsOk} of ${webTools.length} tools loaded.`;
            const tools_status = toolsOk >= webTools.length - 2 ? 'ok' : (toolsOk >= webTools.length / 2 ? 'warn' : 'fail');
            const toolsResponse = await coraRespond('Core Tools check', tools_result, tools_status);
            await speakAndWait(toolsResponse);

            // ================================================================
            // PHASE 4.1: CODE BROWSER - CORA's own codebase viewer
            // ================================================================
            setPhase('code_import', 'running');
            log('PHASE 4.1: CODE BROWSER - CORA CODEBASE', 'phase');
            updateProgress(45, 'Loading CORA code browser...');

            try {
                // Test GitHub API access first
                log('Connecting to Unity-Lab-AI/CORA repository...', 'info');
                const testResp = await fetch('https://api.github.com/repos/Unity-Lab-AI/CORA/contents/');

                if (testResp.ok) {
                    const files = await testResp.json();
                    const fileCount = files.length;
                    const pyFiles = files.filter(f => f.name.endsWith('.py')).length;
                    log(`Repository loaded: ${fileCount} items at root, ${pyFiles} Python files`, 'ok');

                    // Show the full code browser modal
                    const modal = showCodeBrowserModal();
                    log('Code browser opened - browse CORA source!', 'ok');

                    setPhase('code_import', 'ok');
                    const codeResponse = await coraRespond('Code Browser', `My codebase is now viewable. ${fileCount} items loaded. Browse away.`, 'ok');
                    await speakAndWait(codeResponse);

                    // Keep modal open for user to browse (don't auto-close)
                    // User can close it manually with X button
                    await sleep(5000);  // Give time to see it before boot continues
                } else {
                    throw new Error(`GitHub API returned ${testResp.status}`);
                }
            } catch (e) {
                log(`Code browser: ${e.message}`, 'warn');
                setPhase('code_import', 'warn');
                const codeWarn = await coraRespond('Code Browser', 'GitHub API shit the bed. Rate-limited probably.', 'warn');
                await speakAndWait(codeWarn);
            }

            // ================================================================
            // PHASE 4.2: YOUTUBE TEST - Actually embed a video!
            // ================================================================
            setPhase('youtube', 'running');
            log('PHASE 4.2: YOUTUBE VIDEO TEST', 'phase');
            updateProgress(50, 'Finding a video...');

            // Random fun video IDs (short, interesting clips)
            const videoIds = [
                { id: 'dQw4w9WgXcQ', title: 'Classic Rick Roll' },
                { id: 'jNQXAC9IVRw', title: 'First YouTube Video Ever' },
                { id: 'kJQP7kiw5Fk', title: 'Despacito' },
                { id: '9bZkp7q19f0', title: 'Gangnam Style' },
                { id: 'hY7m5jjJ9mM', title: 'Chocolate Rain' }
            ];
            const video = videoIds[Math.floor(Math.random() * videoIds.length)];
            log(`Selected: ${video.title}`, 'ok');
            log('Embedding YouTube video...', 'info');

            // Show video in modal
            const videoModal = showVideoModal(video.id, `CORA - YouTube Test: ${video.title}`);
            log('Video playing in modal', 'ok');

            setPhase('youtube', 'ok');
            // EXACT format from desktop line 1549
            const ytResponse = await coraRespond('YouTube Test', `Found: ${video.title}. Playing sample.`, 'ok');
            await speakAndWait(ytResponse);

            // Auto-close after 5 seconds
            setTimeout(() => videoModal.close(), 5000);

            // ================================================================
            // PHASE 4.3: MODAL WINDOWS - Show actual test modal!
            // ================================================================
            setPhase('modals', 'running');
            log('PHASE 4.3: MODAL WINDOWS TEST', 'phase');
            updateProgress(52, 'Testing modals...');

            // Random quotes like desktop
            const quotes = [
                "The only way to do great work is to love what you do. - Steve Jobs",
                "Innovation distinguishes between a leader and a follower. - Steve Jobs",
                "Stay hungry, stay foolish. - Steve Jobs",
                "Code is like humor. When you have to explain it, it's bad. - Cory House",
                "First, solve the problem. Then, write the code. - John Johnson",
                "The best way to predict the future is to invent it. - Alan Kay"
            ];
            const quote = quotes[Math.floor(Math.random() * quotes.length)];

            log('Opening test modal with quote...', 'info');
            const quoteModal = showQuoteModal(quote);
            log('Modal displayed successfully', 'ok');

            setPhase('modals', 'ok');
            // EXACT format from desktop line 1667
            const modalResponse = await coraRespond('Modal Windows', 'Modal windows working.', 'ok');
            await speakAndWait(modalResponse);

            // Auto-close after speaking
            setTimeout(() => quoteModal.close(), 2000);

            // ================================================================
            // PHASE 5.0: VOICE SYSTEMS
            // ================================================================
            setPhase('voice_sys', 'running');
            log('PHASE 5.0: VOICE SYSTEMS', 'phase');
            updateProgress(55, 'Voice systems...');
            log('Speech Synthesis (TTS) - ' + (ttsEnabled ? 'OK' : 'Fallback'), ttsEnabled ? 'ok' : 'warn');
            const hasSpeechRecog = 'SpeechRecognition' in window || 'webkitSpeechRecognition' in window;
            log('Speech Recognition - ' + (hasSpeechRecog ? 'Available' : 'Not supported'), hasSpeechRecog ? 'ok' : 'warn');
            log('Echo Filter - N/A (web mode)', 'info');
            if (hasSpeechRecog) {
                log('Wake Word - Available (say "Hey CORA")', 'ok');
                initWakeWord();  // Start listening for wake word
            } else {
                log('Wake Word - Not supported in this browser', 'warn');
            }
            setPhase('voice_sys', 'ok');
            // EXACT format from desktop line 1727-1728
            const voice_result = 'Voice systems online.' + (hasSpeechRecog ? ' Wake word active.' : '');
            const voiceResponse = await coraRespond('Voice Systems check', voice_result, 'ok');
            await speakAndWait(voiceResponse);

            // ================================================================
            // PHASE 6.0: EXTERNAL APIs (Location)
            // ================================================================
            setPhase('external', 'running');
            log('PHASE 6.0: EXTERNAL SERVICES', 'phase');
            updateProgress(60, 'Checking location...');

            // Show permission prompt for location
            log('Location permission required...', 'info');
            const locPermResult = await showPermissionPrompt(
                'Location Permission Required',
                'CORA needs your location to provide weather, local news, and location-aware features.',
                '📍'
            );

            let location = null;
            if (locPermResult === 'skip') {
                log('Location permission skipped by user', 'warn');
            } else {
                log('Requesting location...', 'info');
                location = await getLocation();
            }
            if (location?.city) {
                const locStr = [location.city, location.state, location.country].filter(Boolean).join(', ');
                log(`Location: ${locStr}`, 'ok');
                log(`Coordinates: ${location.lat?.toFixed(4)}, ${location.lon?.toFixed(4)}`, 'info');
                // EXACT format from desktop line 1762
                const locResponse = await coraRespond('Location check', `Location: ${locStr}`, 'ok');
                await speakAndWait(locResponse);
            } else {
                log('Location not available or denied', 'warn');
                const locWarn = await coraRespond('Location check', 'Location unavailable.', 'warn');
                await speakAndWait(locWarn);
            }
            setPhase('external', 'ok');

            // ================================================================
            // PHASE 6.1: AUDIO TEST - Uses CORA's playSynth() tool
            // ================================================================
            setPhase('audio', 'running');
            log('PHASE 6.1: AUDIO PLAYBACK TEST', 'phase');
            updateProgress(68, 'Testing audio...');

            // Use CORA's synth tool
            const audioResult = playSynth();
            if (audioResult.success) {
                await new Promise(r => setTimeout(r, 3000));
                log('Audio test complete!', 'ok');
            } else {
                log('Audio test failed: ' + audioResult.error, 'warn');
            }

            // Get weather AND 3-day forecast using wttr.in (free, no API key needed)
            log('Fetching weather and 3-day forecast from wttr.in...', 'info');
            const weather = await getWeather(location?.city || '');
            const forecastData = await get3DayForecast(location?.city || '');

            if (weather.success) {
                log(`Current: ${weather.temp}, ${weather.conditions}`, 'ok');
                log(`Feels like: ${weather.feels_like}`, 'info');
                log(`Humidity: ${weather.humidity}`, 'info');
                document.getElementById('statWeather').textContent = weather.temp;
                document.getElementById('statWeather').className = 'stat-value';

                // Show 3-day forecast
                if (forecastData.success && forecastData.forecast.length > 0) {
                    log('3-Day Forecast:', 'ok');
                    forecastData.forecast.forEach(day => {
                        log(`  ${day.day}: ${day.high}/${day.low} - ${day.conditions}`, 'info');
                    });
                }

                setPhase('audio', 'ok');

                // Build weather report - EXACT format from desktop line 1880-1891
                const tempSpoken = weather.temp.replace('°F', ' degrees').replace('+', '');
                let weather_report = `Current conditions: ${tempSpoken}, ${weather.conditions.toLowerCase()}. `;
                if (forecastData.success && forecastData.forecast.length >= 2) {
                    forecastData.forecast.slice(1, 3).forEach(day => {
                        if (day.conditions) {
                            weather_report += `${day.day} will be ${day.conditions.toLowerCase()} with a high of ${day.high} and a low of ${day.low}. `;
                        } else {
                            weather_report += `${day.day} the high will be ${day.high} and the low will be ${day.low}. `;
                        }
                    });
                }
                // mode='full' for weather like desktop line 1891
                const weatherResponse = await coraRespond('Location and Weather', weather_report, 'ok', 'full');
                await speakAndWait(weatherResponse);
            } else {
                document.getElementById('statWeather').textContent = 'N/A';
                document.getElementById('statWeather').className = 'stat-value na';
                setPhase('audio', 'ok');
                // EXACT format from desktop line 1962
                const audioOnlyResponse = await coraRespond('Audio Playback', `Audio working. Playing ${audioResult.played || 'synth test'}. Weather unavailable.`, 'ok');
                await speakAndWait(audioOnlyResponse);
            }

            // ================================================================
            // PHASE 7.0: NEWS HEADLINES
            // ================================================================
            setPhase('news', 'running');
            log('PHASE 7.0: NEWS HEADLINES', 'phase');
            updateProgress(75, 'Fetching news...');
            log('Fetching top headlines from Google News...', 'info');
            const headlines = await getNews();
            if (headlines.length > 0) {
                log(`Found ${headlines.length} headlines`, 'ok');
                log('Top 3 Headlines:', 'ok');
                headlines.slice(0, 3).forEach((h, i) => log(`  ${i+1}. ${h}`, 'info'));
                setPhase('news', 'ok');
                // EXACT format from desktop line 2055-2057 - clean headlines, mode='full'
                const clean_headlines = headlines.slice(0, 3).map(hl => {
                    let clean = hl.split(' - ')[0] || hl;
                    if (clean.length > 100) clean = clean.substring(0, 97) + '...';
                    return clean;
                });
                const news_data = 'Top headlines: ' + clean_headlines.join('. ');
                const newsResponse = await coraRespond('News Headlines', news_data, 'ok', 'full');
                await speakAndWait(newsResponse);
            } else {
                log('News unavailable', 'warn');
                setPhase('news', 'warn');
                // EXACT format from desktop line 2061
                const newsWarn = await coraRespond('News Headlines', 'No headlines found.', 'warn');
                await speakAndWait(newsWarn);
            }

            // ================================================================
            // PHASE 8.0: VISION TEST - Screenshot + Camera (EXACT match to desktop)
            // Desktop: Takes screenshot, analyzes with llava, SPEAKS the description
            // Then takes camera frame, analyzes with llava, SPEAKS the description
            // Finally gives summary via cora_respond
            // ================================================================
            setPhase('vision', 'running');
            log('PHASE 8.0: VISION TEST', 'phase');
            updateProgress(82, 'Testing vision...');

            let screenshotOk = false;
            let visionCameraOk = false;
            let screen_description = null;
            let camera_description = null;

            // TEST 1: Screenshot capture + llava analysis
            const hasScreenCapture = 'getDisplayMedia' in navigator.mediaDevices;
            log('Screen Capture API - ' + (hasScreenCapture ? 'Available' : 'Unavailable'), hasScreenCapture ? 'ok' : 'warn');

            if (hasScreenCapture) {
                log('Requesting screen capture permission...', 'info');
                try {
                    const ssStream = await navigator.mediaDevices.getDisplayMedia({ video: true });
                    const ssVideo = document.createElement('video');
                    ssVideo.srcObject = ssStream;
                    ssVideo.autoplay = true;
                    await new Promise(r => ssVideo.onloadedmetadata = r);
                    await sleep(500);

                    const ssCanvas = document.createElement('canvas');
                    ssCanvas.width = ssVideo.videoWidth || 1920;
                    ssCanvas.height = ssVideo.videoHeight || 1080;
                    ssCanvas.getContext('2d').drawImage(ssVideo, 0, 0);
                    ssStream.getTracks().forEach(t => t.stop());

                    log(`Screenshot captured: ${ssCanvas.width}x${ssCanvas.height}`, 'ok');
                    screenshotOk = true;

                    // Analyze with llava - CORA describes what she sees
                    log('Analyzing screenshot with llava...', 'info');
                    const ssBase64 = ssCanvas.toDataURL('image/jpeg', 0.7).split(',')[1];
                    try {
                        screen_description = await analyzImageWithLlava(ssBase64, 'Describe what you see on this screen. What application or website is open? What is the user working on?');
                        if (screen_description) {
                            // Clean markdown like desktop
                            screen_description = screen_description.replace(/\*\*([^*]+)\*\*/g, '$1');
                            screen_description = screen_description.replace(/\*([^*]+)\*/g, '$1');
                            screen_description = screen_description.replace(/\n+/g, ' ').replace(/\s+/g, ' ').trim();
                            log(`Vision: ${screen_description.substring(0, 80)}...`, 'ok');
                            // SPEAK the actual description like desktop line 2158
                            await speakAndWait(screen_description);
                        }
                    } catch (e) {
                        log('Screenshot vision analysis skipped', 'warn');
                    }
                } catch (e) {
                    log('Screenshot: ' + (e.name === 'NotAllowedError' ? 'Permission denied' : e.message), 'warn');
                }
            }

            // TEST 2: Camera vision test + llava analysis
            log('Vision camera permission required...', 'info');
            const visionPermResult = await showPermissionPrompt(
                'Vision Camera Permission',
                'CORA needs camera access for the Vision Test to analyze what she sees.',
                '👁'
            );

            if (visionPermResult === 'skip') {
                log('Vision camera skipped by user', 'warn');
            } else {
                log('Testing camera for vision...', 'info');
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                    log('Camera stream acquired for vision test', 'ok');

                    // Create modal with camera view
                    const { content, close } = createDynamicModal('CORA - Vision Test', 800, 600);
                    const visionModal = { close };

                    const video = document.createElement('video');
                    video.srcObject = stream;
                    video.autoplay = true;
                    video.style.cssText = 'width: 100%; height: 100%; object-fit: contain; background: black;';
                    content.style.padding = '0';
                    content.appendChild(video);

                    // Show for 3 seconds like desktop
                    log('Showing camera for vision analysis...', 'info');
                    await sleep(3000);

                    // Capture frame
                    const canvas = document.createElement('canvas');
                    canvas.width = video.videoWidth || 640;
                    canvas.height = video.videoHeight || 480;
                    canvas.getContext('2d').drawImage(video, 0, 0);
                    log(`Vision frame captured: ${canvas.width}x${canvas.height}`, 'ok');

                    // Stop stream
                    stream.getTracks().forEach(t => t.stop());
                    visionCameraOk = true;

                    // Analyze with llava - CORA describes what she sees
                    log('Analyzing camera with llava...', 'info');
                    const camBase64 = canvas.toDataURL('image/jpeg', 0.8).split(',')[1];
                    try {
                        camera_description = await analyzImageWithLlava(camBase64, 'Describe what you see. Is the user visible? What are they doing? What is in the background?');
                        if (camera_description) {
                            // Clean markdown like desktop
                            camera_description = camera_description.replace(/\*\*([^*]+)\*\*/g, '$1');
                            camera_description = camera_description.replace(/\*([^*]+)\*/g, '$1');
                            camera_description = camera_description.replace(/\n+/g, ' ').replace(/\s+/g, ' ').trim();
                            log(`Vision: ${camera_description.substring(0, 80)}...`, 'ok');
                            // SPEAK the actual description like desktop line 2278
                            await speakAndWait(camera_description);
                        }
                    } catch (e) {
                        log('Camera vision analysis skipped', 'warn');
                    }

                    // Close modal
                    setTimeout(() => visionModal.close(), 1000);
                } catch (e) {
                    log('Vision camera: ' + (e.name === 'NotAllowedError' ? 'Permission denied' : e.message), 'warn');
                }
            }

            // Vision summary - EXACT format from desktop line 2313-2321
            let vision_result;
            if (screenshotOk && visionCameraOk) {
                vision_result = "Screenshot and camera both online.";
            } else if (screenshotOk) {
                vision_result = "Screenshot working, no camera.";
            } else if (visionCameraOk) {
                vision_result = "Camera working, screenshot failed.";
            } else {
                vision_result = "Vision systems failed.";
            }
            setPhase('vision', (screenshotOk || visionCameraOk) ? 'ok' : 'warn');
            const visionResponse = await coraRespond('Vision Systems summary', vision_result, 'ok');
            await speakAndWait(visionResponse);

            // ================================================================
            // PHASE 9.0: IMAGE GENERATION - Pollinations test + generate image
            // ================================================================
            setPhase('imagegen', 'running');
            log('PHASE 9.0: IMAGE GENERATION', 'phase');
            updateProgress(90, 'Testing image generation...');

            // Test Pollinations API first
            log('Testing Pollinations API...', 'info');
            const pollinationsOk = await checkPollinations();
            if (pollinationsOk) {
                log('Pollinations API - Online', 'ok');
                document.getElementById('statPollinations').textContent = 'Online';
                document.getElementById('statPollinations').className = 'stat-value';
            } else {
                log('Pollinations API - Unavailable', 'warn');
                document.getElementById('statPollinations').textContent = 'N/A';
                document.getElementById('statPollinations').className = 'stat-value na';
            }

            if (pollinationsOk) {
                // Random dark/creative prompts like desktop
                const imagePrompts = [
                    "cyberpunk city at night, neon lights, rain, dark atmosphere",
                    "dark gothic castle on a mountain, lightning, dramatic sky",
                    "futuristic AI robot with glowing eyes, dark background",
                    "synthwave sunset over digital ocean, purple and pink",
                    "haunted forest with glowing mushrooms, fog, mysterious"
                ];
                const prompt = imagePrompts[Math.floor(Math.random() * imagePrompts.length)];
                const seed = Math.floor(Math.random() * 999999999);

                log(`Prompt: ${prompt}`, 'info');
                log('Generating via Pollinations Flux...', 'info');
                const genStart = Date.now();

                const imageUrl = `https://image.pollinations.ai/prompt/${encodeURIComponent(prompt)}?width=1024&height=768&seed=${seed}&nologo=true`;

                // Show image in modal while it loads
                const imgModal = showImageModal(imageUrl, 'CORA - Generated Image');

                // Wait for image to load and get base64 for llava analysis
                let imageLoaded = false;
                let image_description = null;
                try {
                    const img = new Image();
                    img.crossOrigin = 'anonymous';
                    await new Promise((resolve, reject) => {
                        img.onload = resolve;
                        img.onerror = reject;
                        img.src = imageUrl;
                    });
                    imageLoaded = true;
                    const genTime = ((Date.now() - genStart) / 1000).toFixed(1);
                    log(`Image generated in ${genTime}s`, 'ok');

                    // Convert to base64 and analyze with llava - EXACT like desktop line 2440-2461
                    log('Analyzing generated image with llava...', 'info');
                    const imgCanvas = document.createElement('canvas');
                    imgCanvas.width = img.width;
                    imgCanvas.height = img.height;
                    imgCanvas.getContext('2d').drawImage(img, 0, 0);
                    const imgBase64 = imgCanvas.toDataURL('image/jpeg', 0.8).split(',')[1];

                    try {
                        image_description = await analyzImageWithLlava(imgBase64, 'Describe this image in detail. What do you see? Be specific about the scene, objects, colors, mood, and style.');
                        if (image_description) {
                            // Clean markdown like desktop
                            image_description = image_description.replace(/\*\*([^*]+)\*\*/g, '$1');
                            image_description = image_description.replace(/\*([^*]+)\*/g, '$1');
                            image_description = image_description.replace(/\n+/g, ' ').replace(/\s+/g, ' ').trim();
                            log(`Vision: ${image_description.substring(0, 80)}...`, 'ok');
                        }
                    } catch (e) {
                        log('Image vision analysis skipped', 'warn');
                    }

                    setPhase('imagegen', 'ok');

                    // SPEAK the actual description like desktop line 2461
                    if (image_description && image_description.length > 10) {
                        await speakAndWait(image_description);
                    } else {
                        const imgResponse = await coraRespond('Image Generation', `Image generated in ${genTime}s. Vision failed.`, 'warn');
                        await speakAndWait(imgResponse);
                    }
                } catch (e) {
                    log('Image generation failed: ' + e.message, 'warn');
                    setPhase('imagegen', 'warn');
                    const imgFail = await coraRespond('Image Generation', `Image gen failed: ${e.message.substring(0, 50)}`, 'fail');
                    await speakAndWait(imgFail);
                }

                // Auto-close after viewing
                setTimeout(() => imgModal.close(), 5000);
            } else {
                log('Image generation unavailable - API down', 'warn');
                setPhase('imagegen', 'warn');
                const imgWarn = await coraRespond('Image Generation', 'Image generation unavailable. Pollinations API down.', 'warn');
                await speakAndWait(imgWarn);
            }

            // ================================================================
            // PHASE 10.0: FINAL CHECK (Boot Complete)
            // ================================================================
            setPhase('final', 'running');
            log('PHASE 10.0: FINAL CHECK', 'phase');
            updateProgress(95, 'Final check...');

            // Calculate boot time
            const bootTime = ((Date.now() - bootStartTime) / 1000).toFixed(1);
            document.getElementById('statBootTime').textContent = bootTime + 's';

            // Count results
            let okCount = 0, warnCount = 0, failCount = 0;
            PHASES.forEach(p => {
                if (p.status === 'ok') okCount++;
                else if (p.status === 'warn') warnCount++;
                else if (p.status === 'fail') failCount++;
            });

            log(`Systems: ${okCount} OK / ${warnCount} WARN / ${failCount} FAIL`, 'system');
            log(`Boot time: ${bootTime} seconds`, 'system');

            // Time greeting
            const now = new Date();
            const hour = now.getHours();
            const timeStr = now.toLocaleTimeString('en-US', { hour: 'numeric', minute: '2-digit', hour12: true });
            const dayStr = now.toLocaleDateString('en-US', { weekday: 'long' });
            const monthStr = now.toLocaleDateString('en-US', { month: 'long' });
            const day = now.getDate();
            // Add ordinal suffix for natural speech (1st, 2nd, 3rd, 4th, etc.)
            const ordinal = (d) => {
                if (d > 3 && d < 21) return d + 'th';
                switch (d % 10) {
                    case 1: return d + 'st';
                    case 2: return d + 'nd';
                    case 3: return d + 'rd';
                    default: return d + 'th';
                }
            };
            const dateStr = `${monthStr} ${ordinal(day)}`;
            let greeting;
            if (hour < 12) greeting = `Good morning. Today is ${dayStr}, ${dateStr}. It's ${timeStr}.`;
            else if (hour < 17) greeting = `Good afternoon. Today is ${dayStr}, ${dateStr}. It's ${timeStr}.`;
            else greeting = `Evening. Today is ${dayStr}, ${dateStr}. It's ${timeStr}.`;

            log('═══════════════════════════════════════════════════', 'phase');
            log('           BOOT SEQUENCE COMPLETE', 'phase');
            log('═══════════════════════════════════════════════════', 'phase');
            log(greeting, 'system');

            let statusText;
            if (failCount > 0) {
                statusText = `Got ${failCount} systems that failed. Something's broken.`;
            } else if (warnCount > 0) {
                statusText = `All the important stuff is working. Just ${warnCount} minor issues.`;
            } else {
                statusText = "Everything is up and running perfectly.";
            }
            log(statusText, failCount > 0 ? 'fail' : (warnCount > 0 ? 'warn' : 'ok'));

            updateProgress(100, 'Boot complete!');
            setPhase('final', 'ok');

            // CORA generates her own boot complete response using AI
            log('CORA is waking up...', 'cora');
            try {
                const bootContext = `Boot just finished in ${bootTime} seconds. ${okCount} systems OK, ${warnCount} warnings, ${failCount} failures. ${greeting}`;
                const res = await fetch('http://localhost:11434/api/generate', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        model: 'dolphin-mistral:7b',
                        prompt: `[BOOT COMPLETE - announce in 1-2 sentences with your usual attitude] ${bootContext}`,
                        system: CORA_SYSTEM_PROMPT,
                        stream: false,
                        options: { temperature: 0.9, num_predict: 100 }
                    })
                });
                if (res.ok) {
                    const d = await res.json();
                    const coraResponse = d.response?.trim() || `Boot done in ${bootTime} seconds. What the fuck do you want?`;
                    log(`CORA: "${coraResponse}"`, 'cora');
                    await speakAndWait(coraResponse);
                } else {
                    await speakAndWait(`Boot complete in ${bootTime} seconds. ${statusText} What do you need?`);
                }
            } catch (e) {
                // Fallback if Ollama isn't responding
                await speakAndWait(`Boot complete in ${bootTime} seconds. ${statusText} What do you need?`);
            }

            // ================================================================
            // ABILITIES ANNOUNCEMENT - Like desktop boot_sequence.py
            // ================================================================
            log('─── CORA\'s Abilities ───', 'info');
            log('Vision: see, look, screenshot, camera', 'info');
            log('Images: imagine, draw, generate', 'info');
            log('Web: search, browse, fetch', 'info');
            log('Media: play, pause, volume', 'info');
            log('Tasks: add, list, done, remind', 'info');
            log('Code: explain, write, fix, run', 'info');

            // CORA announces her abilities
            const abilitiesSummary = 'voice, vision, camera, image gen, web search, media playback, code help';
            try {
                const abilitiesRes = await fetch('http://localhost:11434/api/generate', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        model: 'dolphin-mistral:7b',
                        prompt: `[ABILITIES - briefly announce what you can do in 1-2 sentences] I can do: ${abilitiesSummary}. What do you need?`,
                        system: CORA_SYSTEM_PROMPT,
                        stream: false,
                        options: { temperature: 0.9, num_predict: 100 }
                    })
                });
                if (abilitiesRes.ok) {
                    const abData = await abilitiesRes.json();
                    const abilitiesResponse = abData.response?.trim() || `I'm online. I can do: ${abilitiesSummary}. What do you need?`;
                    log(`CORA: "${abilitiesResponse}"`, 'cora');
                    await speakAndWait(abilitiesResponse);
                }
            } catch (e) {
                // Skip abilities announcement if Ollama fails
            }

            log('C.O.R.A IS READY', 'ok');

            // Show chat interface
            document.getElementById('chatSection').classList.add('visible');
            document.getElementById('chatInput').focus();
        }

        function sleep(ms) { return new Promise(r => setTimeout(r, ms)); }

        // ============================================================
        // Chat - Uses CORA_SYSTEM_PROMPT loaded from config/system_prompt.txt
        // ============================================================

        async function sendChat() {
            const input = document.getElementById('chatInput');
            const msg = input.value.trim();
            if (!msg) return;
            input.value = '';
            log(`USER: ${msg}`, 'system');

            // Store user message in ambient context
            addMessageHistory('USER', msg);

            // Show thinking state
            document.getElementById('speechText').textContent = '"Thinking..."';

            // Build context from ambient awareness (speech, messages, camera, screenshot)
            const context = buildAmbientContextPrompt();

            try {
                // Include context in prompt for full awareness
                const fullPrompt = context ? `${context}\n\nUSER: ${msg}` : msg;

                const res = await fetch('http://localhost:11434/api/generate', {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify({
                        model: 'dolphin-mistral:7b',
                        prompt: fullPrompt,
                        system: CORA_SYSTEM_PROMPT,
                        stream: false,
                        options: {
                            temperature: 0.8,
                            num_predict: 500
                        }
                    })
                });
                if (res.ok) {
                    const d = await res.json();
                    const reply = d.response || 'No response';

                    // Store CORA's response in ambient context
                    addMessageHistory('CORA', reply);

                    log(`CORA: "${reply}"`, 'ok');
                    speak(reply);
                } else {
                    log('Ollama error', 'fail');
                    document.getElementById('speechText').textContent = '"Fuck, something broke."';
                }
            } catch (e) {
                log(`Error: ${e.message}`, 'fail');
                document.getElementById('speechText').textContent = '"Ollama is being a bitch right now."';
            }
        }

        document.getElementById('chatInput')?.addEventListener('keypress', e => { if (e.key === 'Enter') sendChat(); });

        // ============================================================
        // View Toggle - Split / Setup Terminal / Console / Status
        // ============================================================

        let viewMode = 'split';  // 'split', 'setup', 'console', 'status'

        function toggleView() {
            const container = document.getElementById('mainContainer');
            const setupTerminal = document.getElementById('setupTerminal');
            const btn = document.getElementById('toggleBtn');

            if (viewMode === 'split') {
                // Show setup terminal (like CORA.bat output)
                viewMode = 'setup';
                setupTerminal.style.display = 'flex';
                container.style.display = 'none';
                btn.textContent = '[ SETUP TERMINAL ]';
            } else if (viewMode === 'setup') {
                // Console only
                viewMode = 'console';
                setupTerminal.style.display = 'none';
                container.style.display = 'grid';
                container.classList.remove('fullscreen-status');
                container.classList.add('fullscreen-console');
                btn.textContent = '[ CONSOLE ONLY ]';
            } else if (viewMode === 'console') {
                // Status only
                viewMode = 'status';
                container.classList.remove('fullscreen-console');
                container.classList.add('fullscreen-status');
                btn.textContent = '[ STATUS ONLY ]';
            } else {
                // Back to split
                viewMode = 'split';
                container.classList.remove('fullscreen-console', 'fullscreen-status');
                btn.textContent = '[ SPLIT VIEW ]';
            }
        }

        // Keyboard shortcut: F key toggles view
        document.addEventListener('keydown', (e) => {
            if (e.key === 'f' || e.key === 'F') {
                if (document.activeElement.tagName !== 'INPUT') {
                    toggleView();
                }
            }
        });

        // ============================================================
        // Modal Handlers
        // ============================================================

        function saveApiKeys() {
            pollinationsKey = document.getElementById('pollinationsKey').value.trim();
            githubToken = document.getElementById('githubToken').value.trim();
            if (pollinationsKey) localStorage.setItem('cora_pollinations_key', pollinationsKey);
            if (githubToken) localStorage.setItem('cora_github_key', githubToken);
            document.getElementById('apiModal').classList.remove('visible');
            runBootSequence();
        }

        function skipApiKeys() {
            document.getElementById('apiModal').classList.remove('visible');
            runBootSequence();
        }

        function openSettings() {
            document.getElementById('apiModal').classList.add('visible');
        }

        function openConsoleWindow() {
            consoleWindow = window.open('console.html', 'cora_console', 'width=800,height=600,menubar=no,toolbar=no');
            if (!consoleWindow || consoleWindow.closed) {
                alert('Popup blocked! Please allow popups for this site to open the console window.');
            }
        }

        function clearAllData() {
            // First warning
            if (!confirm('WARNING: This will delete ALL your CORA data including:\n\n- API keys\n- Chat history\n- Saved preferences\n- All localStorage data\n\nAre you sure?')) {
                return;
            }

            // Second warning
            if (!confirm('FINAL WARNING!\n\nThis action CANNOT be undone.\n\nType "DELETE" in the next prompt to confirm.')) {
                return;
            }

            // Final confirmation
            const confirmation = prompt('Type DELETE to confirm data wipe:');
            if (confirmation !== 'DELETE') {
                alert('Cancelled. Your data is safe.');
                return;
            }

            // Clear everything
            localStorage.clear();
            sessionStorage.clear();

            // Clear cookies for this domain
            document.cookie.split(';').forEach(c => {
                document.cookie = c.replace(/^ +/, '').replace(/=.*/, '=;expires=' + new Date().toUTCString() + ';path=/');
            });

            alert('All CORA data has been wiped.\n\nThe page will now reload.');
            location.reload();
        }

        async function retryOllama() {
            if (await checkOllama()) {
                document.getElementById('gateOverlay').classList.remove('visible');
                // Now check stats server
                if (!(await checkStatsServer())) {
                    document.getElementById('statsGateOverlay').classList.add('visible');
                } else {
                    continueAfterStatsCheck();
                }
            } else {
                alert('Ollama still not responding. Make sure "ollama serve" is running.');
            }
        }

        // ============================================================
        // Init
        // ============================================================

        async function init() {
            // Auto-open console in popup window (safe - won't break if blocked)
            try {
                consoleWindow = window.open('console.html', 'cora_console', 'width=800,height=600,menubar=no,toolbar=no');
            } catch (e) {
                console.log('Console popup blocked');
            }

            renderPhases();
            document.getElementById('pollinationsKey').value = pollinationsKey;
            document.getElementById('githubToken').value = githubToken;

            // Gate 1: Ollama (required)
            if (!(await checkOllama())) {
                document.getElementById('gateOverlay').classList.add('visible');
                return;
            }

            // Gate 2: Stats Server (optional - can skip)
            if (!(await checkStatsServer())) {
                document.getElementById('statsGateOverlay').classList.add('visible');
                return;
            }

            // Stats server running - continue
            continueAfterStatsCheck();
        }

        if (speechSynthesis.onvoiceschanged !== undefined) {
            speechSynthesis.onvoiceschanged = () => {};
        }

        window.addEventListener('load', () => setTimeout(init, 500));
    </script>
</body>
</html>
